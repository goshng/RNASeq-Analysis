User Manual of RNAseq Analysis
==============================
Sang Chul Choi <goshng@yahoo.co.kr>
v0.1.6, July 2012

Introduction
------------
Bacteria can express genes in different intensity in two environments. The number of mRNAs is a direct measure of gene expression. Although a whole mRNA cannot be sequenced by next generation sequencing as of today as far as I know, parts of the whole mRNA can be sequenced. We shred the whole cDNA from an mRNA into smaller pieces, and sequence them to create a large number of reads of the pieces. The more expressed genes, the more reads are sequenced. Next generation sequencing technology can sequence parts of mRNAs after cDNA generation, creating a large number of reads.  We align sequenced reads from a bacterial RNA sample to a reference bacterial genome. Numbers of reads mapped on genes represent the rough expression intensity of those genes. We compare two numbers to state a statistical significance of, if any, the difference. We use four main tools to set up a pipeline that can take advantage of a UNIX cluster although you could use the pipeline on your machine that is equipped with bash shell, i.e., unix, linux, or Mac OS X. First, wetake a quality control step for filtering out raw reads data provided in FASTQ format. Second, we align reads to a bacterial genome, and count reads on annotations of the reference genome. Third, we determine whether genes are differentially expressed using the count data. Fourth, we assess functional associations of differentially expressed genes.

Follow along to acheive the goal mentioned above. Warning! Backup your own raw data files before using commands of *RNAseq Analysis*. We do not guarantee that *RNAseq Analysis* works as you expect (see the license file, +COPYING+ at the base directory of *RNAseq Analysis*, or execute menus *warranty* and *copyright*). It could delete important files of yours. Backup yours and use *RNAseq Analysis* at your own risk. If you have done so, you can keep reading this manual to do the analyses mentioned above. A list of RNA-seq data files are generated by sequencing bacterial transcriptome. We support RNA-seq data *without* strand information at the moment because I simply have only those data. If you have RNA-seq data with strand information, either you should change *RNA-seq Analysis* or contact me to help you (see section <<help,Getting Help>>). Do three steps before executing menus provided by *RNAseq Analysis*. First, place a proper configuration file at +conf+ directory (We refer to a subdirectory of *RNAseq Analysis* without a prepending slash. The manual that you are reading, for example, is referred to as +doc/Manual+ or +doc/Manual.html+. See the section <<convention>> how we typeset words to refer to menus, files, variables in the document). See the section <<Configuration>> to setup your configuration.  Second, install the software packages specified in the configuration file. See the section <<Installation>> for what software packages are needed. Third, prepare a species file at +_ROOTANALYSISDIR_/species+ directory (see also the section <<convention>> to see what _ROOTANALYSISDIR_ means), and the data files that are specified in the species file at proper places. Refer to the section <<SpeciesFile,Species File>> below.  Now, you are ready to start to analyze RNA-seq samples using *RNAseq Analysis*.
 
.Execute the main menu 
----
$ ./run
----

First, call *init-file-system* to create directories for output files. Then, call *choose-species* menu to create directories for your project. See the subsection <<txdb>> for setting up gene annotations. You should configure a set of gene annotations because most of analyses use it. If you configured a gene annotation set by reading the subsection <<txdb>>, then select, for example, *batch3*, and follow the instruction in the menu *batch3* below. Menus might provide scripts in bash or R. Execute them at the base directory of *RNAseq Analysis*. For example, menu *mcl* allows you to execute +job-mcl+ to find core genes. Because they may use Perl or R scripts that are available at the base directories +pl+ or +R+, you must run them at the base directory of *RNAseq Analysis*, which can be different from _ROOTANALYSISDIR_. 

.Execute scripts at the base directory
----
$ cd RNAseq-Analysis
$ bash /path/to/job-mcl
----

anchor:convention[]

Conventions used in this manual
-------------------------------
Menus are in *bold*, and file or software names are in +typewriter+. Shell variables, and variables used in configuration and species files are in _italic_. We could have two main root directories, which could refer to the same directory. We refer to the source directory of *RNAseq Analysis* as the root base directory of *RNAseq Analysis*. We often omit the directory when we refer to a subdirectory of the root base directory. This file that you are reading is called +doc/Manual+ or +doc/Manual.html+. Another main directory is _ROOTANALYSISDIR_, which are intended to be used for storing data. You should set the variable in the configuration file, +conf/README+.

anchor:help[]

Getting Help
------------
Please, post comments or help at
http://code.google.com/p/rnaseq-analysis.

Kick Start
----------
.Start a project
. Create a conf/README file using conf/README.template (see <<Configuration>>)
. Execute menu *init-file-system* (see <<init-file-system>>)

.Create a species file
. Execute menu *choose-species* (see <<choose-species>>)

.Prepare a genomic sequence in FASTA format from NCBI
. Search ftp://ftp.ncbi.nlm.nih.gov/genomes/Bacteria for a complete bacterial genome in FASTA format
. Change the sequence names of the file to a string of 'chr' and an increasing number from 1, or chr1, chr2, and the like

.Prepare a genomic sequence from scratch
. Create a FASTA-format file with DNA sequences
. Set the sequence names to a string of 'chr' and an increasing number from 1

.Prepare a genome annotation file from NCBI complete genomes
. Download the gff file of the chosen species at ftp://ftp.ncbi.nlm.nih.gov/genomes/Bacteria
. Edit the gff file so that chromosome names are chr1, chr2, and the like.
. Execute menu *convert-gff2txdb* (see <<convert-gff2txdb>>)
. Specify the txdb file in your +species+ file

.Prepare a genome annotation file from scratch
. Learn how to use _makeTranscriptDb_ function of BioC R package +GenomicFeatures+ available at http://www.bioconductor.org/packages/release/bioc/html/GenomicFeatures.html[GenomicFeatures]  
. Create a txdb file using the BioC R package

.Test the pipeline of aligning and counting reads
. Prepare a species file for testing purpose (a genome in FASTA format and its annotation in txdb format files are necessary)
. Execute menu *batch3* (see <<batch3>>)
. Run +job-simulate+ at _CACWORKDIR_ to create test FASTQ files
. Run +run-qcalignde.sh+ at _CACWORKDIR_
. Run +job-check+ at _CACWORKDIR_ 

.Align and count reads using FASTA-format DNA sequence and txdb files
. Prepare a species file for testing purpose (a genome in FASTA format and its annotation in txdb format files are necessary)
. Place FASTQ files at _ROOTANALYSISDIR_ directory
. Execute menu *batch3*
. Run +output/your species name/push-data.sh+
. Go to _CACWORKDIR_, and run +run-qcalignde.sh+
. Run +job-de-sum+ at _CACWORKDIR_
. Run +job-stat-plot+ at _CACWORKDIR_
. Run +output/your species name/get-data.sh+

.Compare two gene expression
. Align and count reads using menu *batch3*
. Add _DESEQ_ variable in the species file
. Execute menu *deseq*
. Run +job-deseq+ at base directory of *RNAseq Analysis*
. You might want to use a companion R package, +smutans+

.Find genes that unique to one of two genomes
. Extract protein sequences from two genomes in genbank file format
. Add _REFCDSFASTA1_ and _REFCDSFASTA2_ to the species file
. Execute menu *deseq*
. Run +job-blast+ at base directory of *RNAseq Analysis*

.Find functional associations of differentially expressed genes
. Use smutans R package.

Menus
-----
*RNAseq Analysis* menus provide users with access to commands for analyzing
bacterial RNA-seq data. We assume that we would create output directories at _ROOTANALYSISDIR_ directory, which can be different from the current source root directory of *RNAseq Analysis*.

anchor:init-file-system[]

init-file-system
~~~~~~~~~~~~~~~~
This creates +ROOTANALYSISDIR/output+ directory. As mentioned above, we write +output+ without _ROOTANALYSISDIR_. 
Because the output directory can be large, a
separate hard drive can be mounted and used by symbolic links. Users might want
to create +data+, and +downloads+ directories. The +data+ can be used to store
raw data files including FASTQ, genome, and genome annotation files. The
+downloads+ directory can be used to store other software packages for
installation.

anchor:choose-species[]

choose-species
~~~~~~~~~~~~~~
Create a file in +ROOTANALYSISDIR/species+ directory before calling this menu.
We write +species+ without _ROOTANALYSISDIR_. 
Refer to the 
section <<SpeciesFile,Species File>>. It creates output directories at the
species named subdirectory in +output+ directory. Choose a species and a
repetition number as you are asked. The repetition number can be set in a species file.
Note that we use the following output
directory structure. _DATADIR_ is prefixed by _ROOTANALYSISDIR_.
We use the same output structures in the compute node by
prefixing _C_, and in the remote machine by prefixing _R_. For example,
_CDATADIR_ is similar to _DATADIR_ except _OUTPUTDIR_ being just +output+.
_RDATADIR_ is different from _DATADIR_ in that _OUTPUTDIR_ is replaced by
_ROUTPUTDIR_, which is set in +conf/README+.

anchor:ShellVariable[]

.Output directories
----
SPECIES=[Your species name without spaces]
ROOTANALYSISDIR=[This is the directory where you execute menus]
OUTPUTDIR=$ROOTANALYSISDIR/output
BASEDIR=$OUTPUTDIR/$SPECIES
BASERUNANALYSIS=$BASEDIR/run-analysis
NUMBERDIR=$BASEDIR/$REPETITION
DATADIR=$NUMBERDIR/data
BWADIR=$NUMBERDIR/bwa
RUNANALYSIS=$NUMBERDIR/run-analysis
----
This menu starts to create a directory named after the species file name 
in the main +output+ directory: _BASEDIR_. Each species named directory can
contain numbered directories. The number corresponds to _REPETITION_ or repeated
analyses under the species named project. We would start with a number 1 for the
first repetition. You can specify _REPETITION_ in the species file. Otherwise, it is set to 1 by default.
In a number directory, you can have directories such as
+data+, +bwa+, +run-analysis+, etc.  The +bwa+ directory would contains results
from analyses using *BWA*. In the bash scripts you can access these directories
using shell variables. See +sh/global-variable.sh+ for details.

anchor:convert-gff2txdb[]

convert-gff2txdb
~~~~~~~~~~~~~~~~
We need an annotation file for differential expression study. We 
create a txdb file using a gff or a BED file. 
Because we assume chromosome names to be chr1, chr2, and the like.  
edit the gff file so that the chromosome name is chr1 for a single chromosome
bacterial genome. Bacterial genomes with multiple chromosomes should have
chr1, chr2, etc. You might want to use your own txdb file. Use an R script in +R+ directory to learn to create a txdb file from scratch. See, for example, +R/gff2txdb.R+.

.To create txdb from gff
----
Edit NC_004350.fna and NC_004350.gff so that the chromosome name is chr1.
Rscript R/gff2txdb.R
----

anchor:batch3[]

batch3
~~~~~~
We use the +PRINSEQ+ perl script for quality control.
The data quality control steps includes removing low quality reads,
trimming low quality 3' end parts, timming parts of adapters, and the like.  
We use BioConductor R packages to count reads on a reference annotation of a genome.
Because the shell scripts in *RNA-seq Analysis* create directories and save
output files in them, it is good to know what output directories are created. The
structure of output directories in the local machine where you execute the main
+run+ script is similar to that in the remote machine such as a cluster of
compute nodes. In the cluster, you will have a base directory where you would
submit jobs. This is called a working directory at the cluster, which can be
configured using _CACWORKDIR_ species variable.  In compute nodes, you will also
have base directories that are created in +/tmp+ directory. Under the +/tmp+
directory, you will have a temporary directory; e.g.,
+1209759-3.scheduler.v4linux+, which would be the base directory in a compute
node. Refer to menu *choose-species* for the directory structure in a base
direcotry.

Menu *batch3* creates a number of scripts at _BASEDIR_ 
(See <<ShellVariable,Output directories>>).  One of the shell
scripts, +push-data.sh+, is created at _BASEDIR_ by function _batch3-push-data_
of shell script +sh/batch3.sh+. The shell script transfer 
input files including RNA-seq data files to the remote machine.
You might want to check the script to see what files are copied to the
cluster before executing it because copying large files can take minutes.
I would copy large RNA-seq data files only once. 
You could manually copy some files, or change file paths in the remote computer 
because often the hard drive space at a remote computer can be limited.
The script also creates data, and bwa directories in the cluster.
It copies the reference genome, and the annotation file in txdb format.

.To copy data files to the cluster
----
$ bash output/ua159/push-data.sh
----

Wait! You might want to make sure whether the setup is complete before sending
files and submiting jobs to process those files.  
We take two steps back before we submit jobs to get
the result. First, you go through what variables need to be set in the
species file (see section <<SpeciesFile,Species File>>).
Second, you can use a test data set to check whether your
pipeline is working as expected. To test the pipeline of *RNAseq Analysis*, set 
_FASTQFILES_, and others in the species file

----
FASTQFILES:101 102
QUALITYSCORE101:sanger
QUALITYSCORE102:sanger
ADAPTER101:GATCGGAAGAGCACACGTCTGAACTCCAGTCACCTTGTAATCTCGTATGCCGTCTTCTGCTTG
ADAPTER102:GATCGGAAGAGCACACGTCTGAACTCCAGTCACCTTGTAATCTCGTATGCCGTCTTCTGCTTG
QCALIGNDEWALLTIME:1
----

Warning, again! Backup your important raw data files before using *RNAseq Analysis*. If
you specify _FASTQFILES_ to FASTQ file IDs of your real data, and execute +job-simulate+,
then your FASTQ files will be deleted for good. Use *RNAseq Analysis* at your own risk.

A simulation is not sufficient to check whether the pipeline of counting
short reads mapped on a reference genome is working properly. It is a
necessary condition. It also provides a way of debugging the scripts of *RNAseq Analysis*
when it does not work as expected. The simulation and checking the pipeline takes
minutes while your real data anlaysis might take hours.
You might want to use a development queue of your UNIX cluster so that you do not 
wait for your jobs to complete when queues are full.  
I set both of the wall time to 1 hour
to use a development queue by editting +conf/README+. 

----
QUEUENAME:v4dev
----

Use the following commands at _CACWORKDIR_ to simulate, and check the pipeline of aligning and counting reads on your reference genome.

----
cac$ bash job-simulate
cac$ bash run-qcalignde.sh
cac$ bash job-check
----

The last command, +job-check+, check whether two numbers are similar. 
The ratio of correction means the
proportion of genes with equal numbers of short reads mapped on a reference
genome from the simulation.
The number should be near 1. Often, they were larger than 0.9 but not 0.95. 
Once you are finished with simulation checks, change the type of queue in the
configuration file, and wall time _QCALIGNDEWALLTIME_ in the species file. 
Go through the check list above. Then, submit the job at _CACWORKDIR_.

----
cac$ bash run-qcalignde.sh
----

Once your jobs are finished, run the following command to create count
files.

----
cac$ bash job-de-sum
----

You can also create base quality scores of short reads before and after (Not yet implemented) trimming
3' end of short reads.

----
cac$ bash job-stat-plot
----

Get result files from the cluster.

----
$ bash output/ua159/get-data.sh
----

You will have two kinds of files for determining differentially expressed genes:
+count+ and +count.txt.index+. You can use smutans R package to achieve
this. 

----
output/ua159/1/bwa/count
output/ua159/1/run-analysis/count.txt.index
----

We provide a few count files depending on which parts of gene annotations are used. +count+ uses CDS genes, non-CDS genes (or ribosomal RNAs), and non-genic regions. +count.tx+ uses genic regions including CDS and non-CDS genes. +count.ng+ uses non-genic regions. +count.cds+ uses only CDS genes, and +count.nocds+ uses only non-CDS genes. We use uniquely mapped reads for counting reads for creating files just mentioned above. The cutoff value of mapping quality is _MINMAPQ_. We also use reads with mapping quality less than _MINMAPQ_, and create count files with suffix of +m+. For example, +count.m.cds+ is a count file that contains number of reads multiply mapped on CDS regions.

deseq
~~~~~
We use an R package, +smutans+ (ver. 0.1.9), that comes along with *RNAseq Analysis* for pairwise comparisons of gene expression. The menu uses BioConductor R packages including +DESeq+ to determine differentially expressed genes. It features comparing two sets of protein sequences to determine unique genes to either of the two genomes. First, and the most useful feature is to determine differentially expressed genes. Let *RNAseq Analysis* know what samples you want to compare using _DESEQ_. You have nine samples numbered 1, 6, 7, 8, 11, 12, 13, 19, and 20. Each sample is labeled using _FASTQLABEL_ variable. Use the following three lines in your species file to compare UA159 (1, 19, and 20) and each of other samples.

----
FASTQFILES:1 6 7 8 11 12 13 19 20
FASTQLABEL:UA159 1SM1 11VS1 15JP3 N29 NLML4 NMT4863 UA159 UA159
DESEQ:UA159/1SM1,UA159/11VS1,UA159/15JP3,UA159/N29,UA159/NLML4,UA159/NMT4863
----

Because each repetition is based on a particular reference genome, you would have to execute *deseq* for each repetition. It may be desirable to execute all of the repetitions. This would require many changes to the scripts of *RNAseq Analysis*. The *deseq* menu should provide a bash script that you can run. Run the script at the base root directory of *RNAseq Analysis*. The prepending slash denotes that the path is a full path.

----
$ bash /path/to/job-blast
----

The next feature is to determine genes that are unique to one of two genomes. This may belong to other menus. Because finding unique or similar genes are related with DE study, we have the bash script in menu *deseq*.  We extract protein sequences from a genbank file by using +pl/extractcds.pl+ (FIXME: we have two Perl scripts for extracting protein sequences. Use only one of them. The other is called +bioperl-get-protein.pl+). First, extract protein sequences from the genbank file of your bacterial genome. 

----
perl pl/extractcds.pl -f Genbank file.gbk > file.faa
perl pl/bioperl-get-protein.pl protein -in file.gbk -out file.faa
----

They should produce the same sequences

Add the following two lines to use the +faa+ files in addition to the gff file from the first genome. Use the gff file that is downloaded from NCBI bacterial genomes. The first chromosome is contains more refined annotations that the second genome lacks.  

----
REF1GFF:path/to/file.gff
REFCDSFASTA1:path/to/first.faa
REFCDSFASTA2:path/to/second.faa
----

----
bash /path/to/job-blast
----

This sript creates the following files.

----
_RUNANALYSIS_/genes-chr1-unique.csv
_RUNANALYSIS_/genes-chr1-similar.csv
_RUNANALYSIS_/genes-chr2-unique.csv
_RUNANALYSIS_/genes-chr2-similar.csv
----

File +_RUNANALYSIS_/unique-genes-chr1.csv+ contains genes that are unique to the first set of proteins. The first column is the gene name of the first genome, and the second column is the coverage value that quantifies the proportion of genes with hits in BLAST results in per cent. File +_RUNANALYSIS_/genes-chr1-similar.csv+ contains three columns: the gene name from the first genome, that from the second genome, and the coverage. File +_RUNANALYSIS_/genes-chr2-unique.csv+ is of the same format of +_RUNANALYSIS_/genes-chr1-unique.csv+ but with chr2 genome's unique genes. File +_RUNANALYSIS_/genes-chr2-similar.csv+ contains columns that are similar to file +_RUNANALYSIS_/genes-chr1-similar.csv+ but with one more column of description of chr1's genes, which is the second column of the file +_RUNANALYSIS_/genes-chr2-similar.csv+. 

More detailed accounts for the study of differential expressed genes should be found at the BioConductor R package +DESeq+. The companion R package, +smutans+, contains R scripts that use +DESeq+, and others in BioConductor R packages. Look at files in +package/smutans+ for seeing how to determine differentially expressed genes. Espeically, see the tutorial of the package in +package/smutans/inst/doc/smutans.pdf+.

goseq
~~~~~
The function +smutans.de2Goseq+ uses _Smutans_ object to find functional associations of differentially expressed genes. We prepare three required files to execute the function. First, fetures of genes in the reference genome are a table of 6 columns: chromosome, start, end, gene name, 0, and strand. Second, a file that associates genes and functional terms contains 3 columns: gene name, functional term, and a real value. Third, a file that describe functional terms contains 3 columns: functional term, number of genes that belong to the term, and description of the function. 

I download files for functional association
----
http://www.geneontology.org/gene-associations/submission/gene_association.goa_uniprot.gz
http://www.geneontology.org/ontology/obo_format_1_2/gene_ontology.1_2.obo
ftp://ftp.uniprot.org/pub/databases/uniprot/uniref/uniref90/uniref90.fasta.gz
----

Copy them to _ROOTANALYSISDIR_ and specify their relative locations in your species file
----
GOAPNIPROT:data/goseq/gene_association.goa_uniprot.gz
GOBO:data/goseq/gene_ontology.1_2.obo
UNIREFFASTA:data/goseq/uniref90.fasta.gz
REF1GFF:path/to/file.gff
----

We use the gff file referred by _REF1GFF_ to find the list of genes. We could not use txdb because the +pl/geneonlogy.pl+ is a Perl script which might not be able to use txdb files. We need to associate locus tags with protein IDs so that we can associate locus tags with gene ontology terms. We did not have the association of locus tags and protein IDs in txdb files, yet. Even if we did, we still need to use txdb files in a Perl file. One way to sidestep the problem is to produce a file that is easy to parse using a txdb file, and let the Perl script, +pl/geneontology.pl+ use the file. I think that this is a good direction because I wish to have gene annotations only in a txdb file if I could. So, making a txdb file is the first step of gene annotations.

The three file names should have the extensions of the above.

Use txdb to create +_RUNANALYSIS_/feature.gene+.

----
REFGENOMETXDB:path/to/NC_004350.txdb
----

Run the following two commands.

----
$ bash /path/to/job-feature
$ bash /path/to/job-goseq
----

There are three parameters to tune the *goseq* analysis. First, we could change BLAST options to associate proteins with gene ontology terms. Second, we could change the q-value of determining differentially expressed genes. Third, we could change the q-value of calling gene ontology terms significant. We use 0.05 for the q-value of the third option (This is hard-coded in +smutans+ R package. We usually change the q-value for the second. The first option may be infrequently used because of the long (1 day) execution time of BLAST.

anchor:Configuration[]

mcl
~~~
We use +BLASTP+ and +mcl+ to cluster genes with their protein sequences. The main input file is a FASTA file that contains protein sequences. 

----
MCLFASTA=path/to/mcl.faa
----

Gzip the +mcl.faa+ although you write +mcl.faa+ without +.gz+ extension. The FASTA file should contain sequences with title strings that are easy to parse. The output files from menu *mcl* are the output files from +mclblastline+. 

----
_RUNANALYSIS_/dump.out.all.blastp.tab.*
----

The file contains rows of gene names, each of which is a group of genes. We can use +pl/find-core-gene.pl+ to find core and non-core genes in a given list of genes in a BED file. The BED file can be created using menu *goseq* using +job-feature+ command (see menu *goseq*). You can view the cluster using +cytoscape+. A simple .sif file can be created from mclblastline's dump file, e.g., dump.out.all.blastp.tab.I12. You insert a string, e.g., typeA, after the first column if there are multiple columns. You could open the new .sif file using menu File/Import/Network (Multiple File Types)... in +cytoscape+.

Run +job-mcl+ at the root directory of *RNAseq Analysis*.

----
$ bash /path/to/job-mcl
----


Configuration
-------------
Place a file called README in the directory of +conf+. You can copy
+conf/README.template+ to create +conf/README+. The file contains two kinds of
lines: one for comment, and the other for variable assignment. Comments should
start with # at the first column of a line. 

----
# Comment
----

A variable assignment should start without # at the first column. Variables tend
to be capitalized, and are followed by a colon and a variable value. No spaces
are allowed. Give, for example, a project name as follows.

----
PROJECTNAME:streptoccus
----

All of the output files from *RNAseq Analysis* created in +output+ directory. 
You might want to have a separate hard drive for saving those files because output
files can grow larger than any files in the main source files. 
Set the output directory directly in the
configuration. Set _ROOTANALYSISDIR_ to a full file path. 

----
ROOTANALYSISDIR:/path/to/RNASeq-Analysis-Storage-Directory
----

We allow two modes of using *RNAseq Analysis*: local, and remote (Not yet checked
although we tried to run the local mode). When using local mode, we simply set the 
_CAC_USERNAME_ and _CAC_LOGIN_ to localhost. Currently, _RUNMODE_ is purely for the
purpose of annotation of the configuration file.

.To execute jobs in your local machine
----
RUNMODE:local
----

.To execute jobs in a cluster machine such as CAC: http://www.cac.cornell.edu.
----
RUNMODE:remote
----

Set more variables if you execute jobs in a remote machine. We let the remote
machine be CAC, which is one of the cornell linux clusters. We are not sure what
other linux cluster options are available. If your cluster system is different
from one in CAC, you have to modify parts of the cluster job submission in the shell
scripts. You should set up ssh login without password because we
need log in the remote machine to create directories and copy files back and
forth. See 
http://www.linuxproblem.org/art_9.html
or
http://smbjorklund.no/ssh-login-without-password-using-os-x.
You should set the number of CPUs available in a computing machine.

.To set the number of CPUs for running jobs. 
----
NUMBERCPU:8
----

You need to specify a combination of a user name and a domain name. 

.To set user ID and login address 
----
CAC_USERNAME:yourUserID
CAC_LOGIN:compute.domain.name
----

Set the _CAC_LOGIN_ variable even if you execute jobs in your local machine.

.To set user ID and login address for local mode
----
CAC_USERNAME:yourUserID
CAC_LOGIN:localhost
----

We could have two unix machines: one for computing and another for genome
browser. Use _X11_USERNAME_ and _X11_LOGIN_ to set a machine for genome
browser. *RNAseq Analysis* does not feature functions of creating 
UCSC genome browser tracks.

.To set user ID and login address
----
X11_USERNAME:yourUserIDforGenomeBrowser
X11_LOGIN:genome.browser.domain.name
----

We use the CAC cluster for computing, which may need access information. A batch
script for the cluster would have following header lines.

----
#PBS -A ${BATCHACCESS}
#PBS -q ${QUEUENAME}
#PBS -M ${BATCHEMAIL}
----

The three variables above are replaced by values from the following lines.

----
BATCHACCESS:yourAccessID
QUEUENAME:yourQueueName
BATCHEMAIL:you@email.domain.name
----

Sometime you may not want to get notified from the cluster when jobs are
finished. Then, set _EMAILON_ to FALSE. If you want to get notified, then set it
to TRUE.

----
EMAILON:FALSE
or 
EMAILON:TRUE
----

In the computing machine, you need to have two kinds of directory: one is for
storing input and output files, and the other for executing scripts. Please,
specify a full path not a relative one. You must specify _ROUTPUTDIR_ whatever
_RUNMODE_ is.
While running jobs, input and output files are stored in _ROUTPUTDIR_ directory.
When jobs are finished, files can be copied to the output directory of the base
directory in your local machine. This may be confusing, but convenient because
we can easily delete _ROUTPUTDIR_ directory when we do not need it. We would
want to save files in the output directory in your local machine. Use a full
path not a relative one.

----
ROUTPUTDIR:/path/to/output
----

We use other tools or packages. You need to specify paths for those tools.
Please, find the installation section to know how to install them into the
computing machine.

----
BWA:usr/bin/bwa-0.6.1/bwa
SAMTOOLS:usr/bin/samtools-0.1.18/samtools
PRINSEQ:usr/bin/prinseq-lite-0.17.4/prinseq-lite.pl
PICARD:usr/bin/picard-tools-1.67
CRAMTOOLS:usr/bin/cramtools-0.8.jar
PARSERNASEQ:usr/bin/ParseRNAseq
PYTHON:/opt/epd/bin/python2.7
CUTADAPT:/home/fs01/sc2265/usr/bin/cutadapt-1.0/cutadapt
CACRSCRIPT:/home/fs01/sc2265/Downloads/r-devel/b/bin/Rscript
----

anchor:txdb[]

txdb
~~~~
The annotation of a genome afffects most of analyses such as differential expresssion of genes, functional association, and gene clusters. You had better to decide what gene annotations you use in *RNAseq Analysis*. A genome in genbank format from NCBI is one of the source of genome annotations. Sometimes, we use a gff file from NCBI that accompanies the genbank file. You could use +pl/bioperl-get-protein.pl+ to create a gff file from a genbank file. Because annotation files in gff format keep changing, we could not prepare a menu in *RNAseq Analysis*. Many of the R scripts in *RNAseq Analysis* use BioConductor R packages. A BioConductor R package, called +GenomicFeatures+, provides a method, _makeTranscriptDb_ that creates a txdb file. We use a gff file to create a txdb file. As I mentioned earlier, it is not trivial to create a txdb using a gff file although it is easy to use _makeTranscriptDb_. So, I want to write down some steps of R scripts to create a txdb file using a gff file.  The chromosome names should be named chr with a number.

Consider that you have a file, named +NC_004350.gff+, in gff format. I downloaded the file from NCBI Bacterial genome FTP site, and replaced the "NC_004350.2" with "chr1" for handling the file more easily. Start an R session and load BioConductor R pacakges, +rtracklayer+ and +GenomicFeatures+. We use a function _import.gff3_ of +rtracklayer+ to import the gff file.

----
> gffFile <- "NC_004350.gff"
> library(rtracklayer)
> library(GenomicFeatures)
> sm.gff <- import.gff3(gffFile)
----

The function, _import.gff3_, is helpful in reading a gff file. The output variable _sm.gff_ is a _RangedData_ object, contains a column called _type_ that we use to subset genes and CDS regions of _sm.gff_.

----
> sm.gene <- sm.gff[sm.gff$type=="gene",]
> sm.CDS <- sm.gff[sm.gff$type=="CDS",]
----

The _sm.gene_ object contains all of the annotations including mRNA, rRNA, and others. 

----
> unique(sm.gff$type)
[1] region gene   CDS    rRNA   exon   tRNA 
Levels: CDS exon gene region rRNA tRNA
----

We call eventually _makeTranscriptDb_ to create a txdb variable, which is saved using _saveFeatures_ function. These two functions are part of BioConductor R package, +GenomicFeatures+. 

----
> txdb <- makeTranscriptDb (transcripts, splicings, chrominfo=chrominfo)
> gffFileBasename <- unlist(strsplit(gffFile,"\\."))[1]
> saveFeatures(txdb,file=paste(gffFileBasename,"txdb",sep="."))
----

You may have noticed three R variables, _transcripts_, _splicings_, and _chrominfo_. You might want to refer to the help page for _makeTranscriptDb_. The first variable is an R data frame with id, name, chrom, strand, start, and end. Prepend the 6 arguments with tx with a underscore as follows.

----
> transcripts <-                                                                  
    data.frame( tx_id=seq(length(sm.gene$locus_tag)),                             
                tx_name=sm.gene$locus_tag,                                        
                tx_chrom=sm.gene$space,                                           
                tx_strand=sm.gene$strand,                                         
                tx_start=start(sm.gene),                                          
                tx_end=end(sm.gene) )
> head (transcripts)
  tx_id tx_name tx_chrom tx_strand tx_start tx_end
1     1  SMU_01     chr1         +      194   1552
2     2  SMU_02     chr1         +     1708   2844
3     3  SMU_05     chr1         +     3106   3297
----

Let us have _chrominfo_ before explaining how to create _splicing_ because _chrominfo_ is much easier to explain. Our example of a gff file contains a single chromosome, which we renamed it chr1. The length is 2032925. Although it is a circular genome, we set it the corresponding option to FALSE (I do not know what side effect of this is). If there are multiple chromosomes, use R vectors for chrom and length, two of which should parallel side by side.

----
> chrominfo <-                                                                    
    data.frame( chrom="chr1",                                             
                length=2032925,                                            
                is_circular=FALSE )
> chrominfo
  chrom  length is_circular
1  chr1 2032925       FALSE
----

A transcript can consist of multiple exons in eukaryotes. The _splicing_ data frame contains exons and their membership in the _transcripts_ data frame. For example, the following is given by the help page of _makeTranscriptDb_ object. We have three transcripts. The first row of _splicing_ data frame represents one and the only exon, which also encodes a protein. The next three exons of 2nd, 3rd, and 4th rows of _splicing_ data frame correspond to three exons that belong to the 2nd transcript. We specify their identifiers in the 2nd transcript using exon's rank. The three exons also encode proteins. The 3rd transcript contains two exons that does not encode a protein, which is denoted by NA in cds start and end.

----
> ?makeTranscriptDb
...
     transcripts <- data.frame(
                        tx_id=1:3,
                        tx_chrom="chr1",
                        tx_strand=c("-", "+", "+"),
                        tx_start=c(1, 2001, 2001),
                        tx_end=c(999, 2199, 2199))
     splicings <-  data.frame(
                        tx_id=c(1L, 2L, 2L, 2L, 3L, 3L),
                        exon_rank=c(1, 1, 2, 3, 1, 2),
                        exon_start=c(1, 2001, 2101, 2131, 2001, 2131),
                        exon_end=c(999, 2085, 2144, 2199, 2085, 2199),
                        cds_start=c(1, 2022, 2101, 2131, NA, NA),
                        cds_end=c(999, 2085, 2144, 2193, NA, NA))
     
     txdb <- makeTranscriptDb(transcripts, splicings)
...     
----

You have to make sure that you have _splicings_ object correctly. There is no unique way of creating the object. We describe two ways. First, CDS might have an attribute that tells us to which gene that the CDS belongs. The NCBI's gff file contains Parent column, which specifies CDS's membership. We can find the parent gene by searching _sm.gene_ ID for the parent of a CDS.

----
> colnames(sm.CDS)
 [1] "source"        "type"          "score"         "strand"       
 [5] "phase"         "Dbxref"        "gbkey"         "gene"         
 [9] "gene_synonym"  "genome"        "ID"            "Is_circular"  
[13] "locus_tag"     "mol_type"      "Name"          "Note"         
[17] "old_locus_tag" "Parent"        "product"       "protein_id"   
[21] "pseudo"        "strain"        "transl_table" 
----

Make sure that each CDS has a single parent, which should be true of bacterial genomes. I intentially added ">" so that you cannot just copy and paste the code. You have to see what each step does. We iterate over all of the gene ID to construct _grCDS.start_ and _grCDS.end_. 

----
> x <- c()
> y <- c()
> z <- unlist(sm.CDS$Parent)
> stopifnot(nrow(sm.CDS)==length(unlist(sm.CDS$Parent)))
for (i in sm.gene$ID) {
  if (sum(z == i) > 0) { # Check if the CDS contains the gene
    if (length(start(sm.CDS)[z == i]) != 1) { # Check if there is a unique parent gene for CDS.
      print(paste("Check",gffFile))
      print(start(sm.CDS)[z == i])
      stop(paste("There are multiple CDS for gene",i))
    }
    x <- c(x,start(sm.CDS)[z == i]) # Add the start position of the CDS of the gene
    y <- c(y,end(sm.CDS)[z == i])   # Add the end position.
  } else {
    x <- c(x,NA) # Add NA if the CDS set does not contain the gene
    y <- c(y,NA) # Add NA for the end position.
  }
}
> grCDS.start <- x
> grCDS.end <- y
> rm(i,x,y,z)
----

Then, we can create _splicings_ data frame, which is used to create a txdb file.

----
> splicings <-                                                                    
    data.frame( tx_id=seq(length(sm.gene$locus_tag)),                             
                exon_rank=seq(length(sm.gene$locus_tag)),                         
                exon_start=start(sm.gene),                                        
                exon_end=end(sm.gene),                                            
                exon_name=sm.gene$locus_tag,                                      
                cds_start=grCDS.start,                                            
                cds_end=grCDS.end )
----

FIXME: Sometimes, CDS parent information may unavailable. The second approach is to use CDS positions to find their parent genes. 

Add more attributes for genes such as protein ID, product, or some other annotations. This seems not available in _makeTranscriptDb_ function at the moment. We might need to use _sm.gff_ or gff file to add more annotation to CDS or transcripts. 

How do we use the txdb? We take transcripts and CDS using _transcripts_ and _cds_ functions of +GenomicFeatures+ R package. Subset CDS of _transcripts_ by compairing transcript IDs. Then, we add a type column. This can be a step where I can add more annodataion. This operation gives us txdb with and without CDS regions.

----
library(rtracklayer)
library(GenomicFeatures)
txdb <- loadFeatures("1.txdb")
feature.tx <- transcripts(txdb)
feature.cds <- cds(txdb,columns="tx_id")
stopifnot(length(feature.cds) == length(unlist(elementMetadata(feature.cds)$tx_id)))
x <- elementMetadata(feature.tx)$tx_id %in% unlist(elementMetadata(feature.cds)$tx_id)
feature.cds <- feature.tx[x]
elementMetadata(feature.cds) <- data.frame(tx_id=elementMetadata(feature.cds)$tx_id, tx_name=elementMetadata(feature.cds)$tx_name,type="CDS")
----

We also have transcripts without CDS, and combine _feature.cds_ and _feature.nocds_ to create _feature.txnc_. 

----
feature.txnc <- feature.cds
feature.nocds <- feature.tx[!x]
if (length(feature.nocds) > 0) {                                                
  elementMetadata(feature.nocds) <- data.frame(tx_id=elementMetadata(feature.nocds)$tx_id, tx_name=elementMetadata(feature.nocds)$tx_name,type="NOCDS")
  feature.txnc <- c(feature.txnc,feature.nocds)                                 
}    
----

We also find the rest of regions as non-genic loci. The combined object, _feature.txnc_, contains three types, CDS, NOCDS, and NG (non-genic). 

----
feature.ng <- transcripts(txdb)                                                 
strand(feature.ng) <- '*'                                                       
feature.ng <- gaps(reduce(feature.ng))                                          
feature.ng <- feature.ng[strand(feature.ng)=='*']
if (length(feature.ng) > 0) {                                                   
  x <- seq(from=length(feature.tx)+1,to=length(feature.tx)+length(feature.ng))  
  y <- paste("NC",x,sep="_")                                                    
  elementMetadata(feature.ng) <- data.frame(tx_id=x,tx_name=y,type="NG")        
  rm(x,y)                                                                       
  feature.txnc <- c(feature.txnc,feature.ng)                                    
}
> Rle(elementMetadata(feature.txnc)$type)
'factor' Rle of length 3743 with 3 runs
  Lengths:  1960    82  1701
  Values :   CDS NOCDS    NG
Levels(3): CDS NOCDS NG
----

We can export the combined R object _feature.txnc_ to save it to a BED file. The function _export_ uses the file extension to recognize the export file format. Before exporting _feature.txnc_, we populate the names with transcript names, which should be used as values of the name column of the BED foramt. Otherwise, only dots will be printed out at the name column in a BED file.

----
names(feature.txnc) <- elementMetadata(feature.txnc)[,"tx_name"]
export(feature.txnc,"txnc.bed")
----

Because the procedure is not standarized, you must make sure that your annotations are correct. You could make sure whether the extraction of CDS regions from your _feature.txnc_ was correctly performed using Galaxy web interface that was available at https://main.g2.bx.psu.edu. Use "Upload File" tool to send the gff file +NC_004350.gff+, and convert it to a BED file using "GFF-to-BED" tool. Use "Filter" tool to divide the BED file to a part of plus strand and another of minus strand. Download the two files and concatenate them to a file. Compare the concatenated file and +txnc.bed+. They must be the same except name columns. You may need to verify the correctness of the annotation txdb using other methods for cross check.

anchor:Installation[]

Installation
------------
Software packages used in *RNAseq Analysis* should be installed on
the local and/or remote machine. First, create directories called +downloads/build+. 
If you use your local machine, follow this instruction in your machine.
You have to log in your remote machine if you use other machine such as a linux
cluster.

----
$ mkdir -p downloads/build
----

Create a +bin+ directory to save executable files.

----
$ mkdir -p $HOME/usr/bin
----

BWA
~~~
Dowanload BWA source code available at http://bio-bwa.sourceforge.net. 

----
$ downloads/bwa-0.6.1.tar.bz2
----

Extract the file and compile it.

----
$ cd downloads/build
$ tar jxf ../bwa-0.6.1.tar.bz2
$ cd bwa-0.6.1; make; cd ..
$ mv bwa-0.6.1 $HOME/usr/bin
----

Edit +conf/README+ if necessary; Add the following line. The base directory is
$HOME or your home directory. Shell variable $BWA is replaced by
+/home/userid/usr/bin/bwa-0.6.1/bwa+.

----
BWA:usr/bin/bwa-0.6.1/bwa
----

SAMTools
~~~~~~~~
Download SAMtools available at http://samtools.sourceforge.net.

----
$ downloads/samtools-0.1.18.tar.bz2
----

Extract the file and compile it.

----
$ cd downloads/build
$ tar jxf ../samtools-0.1.18.tar.bz2
$ cd samtools-0.1.18; make; cd ..
$ mv samtools-0.1.18 $HOME/usr/bin
----

Edit +conf/README+ if necessary; Add the following line. The base directory is
$HOME or your home directory. Shell variable $SAMTOOLS is replaced by
+/home/userid/usr/bin/samtools-0.1.18/samtools+.

----
SAMTOOLS:usr/bin/samtools-0.1.18/samtools
----

prinseq
~~~~~~~
Download a prinseq lite version available at http://prinseq.sourceforge.net.
Extract the file and move the directory.

----
$ cd downloads/build
$ tar zxf ../prinseq-lite-0.17.4.tar.gz
$ mv prinseq-lite-0.17.4 $HOME/usr/bin
----

Edit +conf/README+ if necessary; Add the following line. The base directory is
$HOME or your home directory. Shell variable $PRINSEQ is replaced by
+/home/userid/usr/bin/prinseq-lite-0.17.4/prinseq-lite.pl+.

----
PRINSEQ:usr/bin/prinseq-lite-0.17.4/prinseq-lite.pl
----

cutadapt
~~~~~~~~
Download cutadapt available at http://code.google.com/p/cutadapt.

----
$ cd downloads/build
$ tar zxf ../cutadapt-1.0.tar.gz 
$ mv cutadapt-1.0 $HOME/usr/bin
----

Edit +conf/README+ if necessary; Add the following line. The base directory is
$HOME or your home directory. Note that _CUTADAPT_ must be the absolute path of
the binary executable. We would call python with the executable. Do not use a
relative file path.

----
CUTADAPT:/home/user/usr/bin/cutadapt-1.0/cutadapt
----

NOTE:The following prorams need to be checked. I have not yet time to edit the
following description of the installation.

----
$ python setup.py build
$ sudo python setup.py install
CUTADAPT:/usr/local/bin/cutadapt
----

.To install cutadapt in a linux cluster
----
python2.7 setup.py build_ext -i
python2.7 path/to/cutadapt --help
----

python
~~~~~~
Set _PYTHON_ variable to a file.

----
PYTHON:/path/to/python2.7
----

Rscript
~~~~~~~
Install R version 2.15 and Bioconductor 2.10. Set _CACRSCRIPT_ variable.

----
CACRSCRIPT:/path/to/Rscript
----

In R, run the following line of
----
source("http://www.bioconductor.org/biocLite.R")
----

to install the R packages:

----
biocLite("DESeq")
biocLite("ShortRead")
biocLite("rtracklayer")
biocLite("GenomicRanges")
biocLite("VariantAnnotation")
biocLite("GenomicFeatures")
biocLite("Rsamtools")
biocLite("edgeR")
biocLite("DEGseq")
----

You also need to install an R package, *smutans*, that accompanies *RNAseq Analysis*. The R package uses +DESeq+.

.To install smutans R package.
----
R CMD install smutans_0.1.9.tar.gz
----

BLAST
~~~~~
We will use BLAST for functional association of differentially expressed genes.
We do not provide features of *RNAseq Analysis* that uses +BLAST+.
ftp://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/LATEST/ 
ncbi-blast-2.2.25+-x64-linux.tar.gz
is used in the cluster. You could download a dmg for mac installation, which was installed at the following directory:

----
/usr/local/ncbi/blast/bin
----

Because we use a relative path for programs, copy executables in the bin directory to +usr/bin+ of your home at the local machine or at the remote one. 

.Add the following lines to +conf/README+ for global configuration
----
MAKEBLASTDB:usr/bin/makeblastdb
BLASTN:usr/bin/blastn
BLASTP:usr/bin/blastp
----

Refer to documentation available in http://www.ncbi.nlm.nih.gov/books/NBK1762.

+deseq-blast+	       

We use +uniprot90+ for functional association.
wget ftp://ftp.uniprot.org/pub/databases/uniprot/uniref/uniref90/uniref90.fasta

BioPerl
~~~~~~~
Install BioPerl. We need it when analyzing BLAST result files.

MUSCLE
~~~~~
We do not provide features of *RNAseq Analysis* that uses +MUSCLE+.
http://www.drive5.com/muscle/downloads3.8.31/muscle3.8.31_i86linux64.tar.gz

.Create a +build+ directory at the base directory +run/rnaseq/110111+ of a cluster.
----
cac:run/rnaseq/110111/build/muscle3.8.31_i86linux64
cac:run/rnaseq/110111/build/ncbi-blast-2.2.25+
cac:run/rnaseq/110111/build/RNAz-2.1
----

subread
~~~~~~~
We have not implemented a feature of *RNAseq Analysis* that uses +subread+. 
Download subread available at http://subread.sourceforge.net. 
Another short read aligner. This could be used in menu *batch3*.
As of April 2012, it did not support Mac OS X. Authors said that they would make
a Mac OS X version available in 2012.

BOWTIE
~~~~~~
We have not yet used +BOWTIE+ in *RNAseq Analysis*.
Download BOWTIE and install it under +src+ directory. The following command
should print a help message from it. Edit +conf/README+ if necessary.
----
$ src/bowtie-0.12.7/bowtie
----

segemehl
~~~~~~~~
We have not yet used +segemehl+ in *RNAseq Analysis*.
Download segemehl at http://www.bioinf.uni-leipzig.de/Software/segemehl. You
could compile the source in this repository of rnaseq-analysis.
http://www.bioinf.uni-leipzig.de/Software/segemehl/
----
$ cd src/segemehl_0_0_9_4
$ make
----

Picard
~~~~~~
We have not yet implemented a feature of *RNAseq Analysis* that uses +Picard+. We might use this when ``cramming'' FASTQ files.
Download Picard available at http://picard.sourceforge.net. Unzip the file and
move directories.

----
$ cd downloads/build
$ unzip ../picard-tools-1.65.zip
$ mv picard-tools-1.65 $HOME/usr/bin
$ mv snappy-java-1.0.3-rc3.jar $HOME/usr/bin
----

Edit +conf/README+ if necessary; Add the following line. The base directory is
$HOME or your home directory. Shell variable $PICARD is replaced by
+/home/userid/usr/bin/picard-tools-1.65+.

----
PICARD:usr/bin/picard-tools-1.65
----

CRAM Toolkit
~~~~~~~~~~~~
We have not yet implemented a feature of *RNAseq Analysis* that uses +cram+.
Download CRAM Toolkit available at http://www.ebi.ac.uk/ena/about/cram_toolkit.
Move the file to +$HOME/usr/bin+.

----
$ cd downloads/build
$ mv ../cramtools.jar $HOME/usr/bin
----

Edit +conf/README+ if necessary; Add the following line. The base directory is
$HOME or your home directory. Shell variable $CRAMTOOLS is replaced by
+/home/userid/usr/bin/cramtools.jar+.

----
CRAMTOOLS:usr/bin/cramtools.jar
----

FASTAX-Toolkit
~~~~~~~~~~~~~~
We have not yet used this tool kit in *RNAseq Analysis*.
Download FASTAX-Toolkit at
http://hannonlab.cshl.edu/fastx_toolkit/fastx_toolkit-0.0.13.tar.bz2
and 
http://hannonlab.cshl.edu/fastx_toolkit/libgtextutils-0.6.tar.bz2.

TopHat and Cufflinks
~~~~~~~~~~~~~~~~~~~~
We have not yet used +TopHat+ in *RNAseq Analysis*.
Download the Mac OS X x86_64 binary from http://tophat.cbcb.umd.edu[here].
Untar it and add the directory to PATH so that I can run it without full path.
Download the Mac OS X x86_64 binary from http://cufflinks.cbcb.umd.edu[here].
Untar it and add the directory to PATH so that I can run it without full path

RNAz
~~~~
We do not provide features of *RNAseq Analysis* that uses +RNAz+.
http://www.tbi.univie.ac.at/~wash/RNAz/ or
https://github.com/wash/rnaz.

----
wget http://www.tbi.univie.ac.at/~wash/RNAz/RNAz-2.1.tar.gz
wget http://www.tbi.univie.ac.at/RNA/ViennaRNA-1.8.5.tar.gz
----

In the CAC:
----
mkdir b
cd b
../configure --prefix=$HOME/usr 
----

RNAplex
~~~~~~~
We do not provide features of *RNAseq Analysis* that uses +RNAplex+.
http://www.bioinf.uni-leipzig.de/Software/RNAplex/

Vienna RNA Package
~~~~~~~~~~~~~~~~~~
We do not provide features of *RNAseq Analysis* that uses Vienna RNA package.
http://www.tbi.univie.ac.at/~ivo/RNA/RNAplfold.html

anchor:SpeciesFile[]

Species File
------------
A setup for *RNAseq Analysis* is described in a species file in +species+ directory.  The +species+ directory should be placed at _ROOTANALYSISDIR_. Choose a species name for a species file. Create a file with the name, and place it in the directory of +species+. You can use +species/template+. As the +conf/README+ file, a species file contains two kinds of lines: one for comment, and the other for variable assignment. Comments should start with # at the first column of a line. 

.Comment in a species file
----
# Comment
----

A variable assignment should start without # at the first column. Variables tend to be capitalized, and are followed by a colon, then a variable value. No spaces are allowed.  

.Variable in a species file
----
VARIABLE:value
----

Check a list of species file variables in the following.  Note that we must have a single variable. Multiple instances of species file variables would cause problems.

.Check the following spcies file variables
. fastq files
. quality score scheme
. adapter sequences
. repetition in _REPETITION_ (optional)
. fastq file indices in _FASTQFILES_
. fastq file labels in _FASTQLABEL_
. cluster working directory in _CACWORKDIR_
. reference genome fasta file in _REFGENOMEFASTA_
. reference genome annotation TrancriptDb file in _REFGENOMETXDB_
. reference genome annotation file in _REFGENOMEGFF_ (optional)
. pipeline wall time in _QCALIGNDEWALLTIME_
. minimum alignment mapping quality in _MINMAPQ_
. minimum base quality to trim 3' end in _MINTRIMQ_
. Rscript path in _CACRSCRIPT_

fastq files
~~~~~~~~~~~
First, place fastq files in your _ROOTANALYSISDIR_ in the computer. Then, specify locations of the fastq files. Variables are prefixed _FASTQ_ with three-digit numbers with zeros prepended. Currently, the file extension must be fq and files must be zipped using +gzip+. So, files should end with +fq.gz+. Use a path relative to _ROOTANALYSISDIR_ directory.

.fastq files
----
FASTQ001:path/to/file1.fq.gz
FASTQ002:path/to/file2.fq.gz
----

The path _ROOTANALYSISDIR_ must be set in the configuration file, or
+conf/README+ (see the section <<Configuration>>).

.Full path of a root for storing data
----
ROOTANALYSISDIR:/path/to/RNASeq-Analysis
----

The full path to the FASTA file will be

----
/path/to/RNASeq-Analysis/path/to/file1.fq.gz
----

quality score
~~~~~~~~~~~~~
Quality scores can be phred33 or phred64. Use a value of "illumina" for phred64, and a value of "sanger" for phred33.  Variables are prefixed _QUALITYSCORE_ with three-digit numbers with zeros prepended. Because each fastq file has a distinct quality score scheme, you need to specify quality score schemes as many times as fastq files.

.Quality scores schemes
----
QUALITYSCORE001:illumina
QUALITYSCORE002:sanger
----

adapter sequences
~~~~~~~~~~~~~~~~~
Each fastq file is associated with an Illumina adapter sequence. They must be specified, and are used to remove adapter sequences in short reads.  Variables are prefixed _ADAPTER_ with three-digit numbers with zeros prepended. 

.Adapter sequences
----
ADAPTER001:GATCGGAAGAGCACACGTCTGAACTCCAGTCACCGATGTATCTCGTATGCCGTCTTCTGCTTG
ADAPTER002:GATCGGAAGAGCACACGTCTGAACTCCAGTCACTGACCAATCTCGTATGCCGTCTTCTGCTTG
----

repetition
~~~~~~~~~~
You might have want to repeat the procedure of aligning and counting reads on different reference genomes, or different annotations. Use _REPETITION_ variable to store results from different reference genomes or annotations. If not specified, the default is 1.

fastq file indices and labels
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
You may wish to process all of fastq files, or some of them. Specify which fastq files you wish to use using _FASTQFILES_ variable. Use _FASTQLABEL_ to group different fastq files. Labels are used for the purpose of differential expression study. They are saved in a file called +count.txt.index+. Use numbers beyond the largest IDs of FASTQ files when creating test FASTQ files for the purpose of testing the pipeline of *RNAseq Analysis*.

.File indices for fastQ files
----
FASTQFILES:1 2
FASTQLABEL:UA159 TW1
----

cluster working directory
~~~~~~~~~~~~~~~~~~~~~~~~~
After creating all of the scripts in your local machine, you would submit jobs at a directory in the cluster. You need to create the directory while you prepare a *RNASeq Analysis* by editing a species file.

.Cluster working directory
----
CACWORKDIR:run/rnaseq/022712
----

.Create the working directory
----
cac> mkdir -p run/rnaseq/022712
----

reference genome and annotation
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Set the path of a reference genome genbank file in _REFGENOMEFASTA_. Use a path relative to your _ROOTANALYSISDIR_ directory. For example, you would have a directory called +data+ in *RNASeq-Analysis* _ROOTANALYSISDIR_ directory. Use a path relative to _ROOTANALYSISDIR_ directory. 

----
REFGENOMEFASTA:data/to/NC_004350.fna
----

To map short reads on a reference genome, you must specify the file paths of reference genome files and gene annotations. The reference genome sequence is in FASTA format. Each sequence represents a contiguous genome. A complete bacterial genome can be a single sequence because only one chromosome is available. Genomes can consist of multiple chromosomes when the genome sequencing is incomplete or the genome contains multiple chromosomes. The FASTA file would contain multiple FASTA sequences. Because it is convenient to assume sequence names, we rename each sequence using chromosome numbers in the FASTA file of a genome. For example, the first line of a FASTA file for a reference genome must be 

----
>chr1
----

Change the names of other sequences accordingly: chr2 for the second chrmosome. An incomplete bacterial genome would have multiple contigs, each of which can be considered a chromosome. Use a path relative to _ROOTANALYSISDIR_ directory. We also have to change chromsome name in a gff file as well. If there are other annotation files, change the names accordingly.

.Reference genomes
----
REFGENOMEGFF:path/to/NC_004350.gff
----

We can convert a gff file to a txdb file. See +R/gff2txdb.R+ or +R/xbasegff2txdb.R+ for detail. Use a path relative to _ROOTANALYSISDIR_ directory. 

----
REFGENOMETXDB:path/to/NC_004350.txdb
----

When gff files are not available, use +pl/bp_genbank2gff3.pl+ to convert a genbank file to a gff file. 

----
cat file.gbk | perl pl/bp_genbank2gff3.pl -in stdin -out stdout > file.gff
----

pipeline wall time
~~~~~~~~~~~~~~~~~~
Set the maximum compute time for aligning and counting short reads.

.pipeline wall time
----
QCALIGNDEWALLTIME:8
----

minimum alignment mapping quality
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
We filter out short reads with bad mapping quality scores.

----
MINMAPQ:30
----

Use _DESEQ_ to use menu *deseq*. A pairwise comparison is performed for each pair of _FASTQLABEL_. Pairwise comparisons are separated by a slash.

----
DESEQ:UA159/1SM1,UA159/11VS1,UA159/15JP3,UA159/N29,UA159/NLML4,UA159/NMT4863
----

minimum base quality to trim 3' end
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
We trim the 3' end of short reads using a threshold of base quality.

----
MINTRIMQ:20
----

Files
-----

AUTHORS
~~~~~~~
Sang Chul Choi uses Perl, R, and NGS programs to analyze bacterial transcriptome. Charles Danko guides the development in the early stage of the development of *RNAseq Analysis*.

COPYING
~~~~~~~
The GNU General Public License. 

INSTALL
~~~~~~~
The instruction of installing RNAseq Analysis.

NEWS
~~~~
A list of user-visible changes to *RNAseq Analysis* worth mentioning. 

R
~~
R scripts.

README
~~~~~~
A README of the root directory.

THANKS
~~~~~~
People help the development of *RNAseq Analysis*.

TODO
~~~~
New features of *RNAseq Analysis*.

bin
~~~
Binary or shell script files. 

c
~~
A shell script that uses +asciidoc+ to convert +doc/Manual+ to an html file.

conf
~~~~
The *RNAseq Analysis* is configured using the +README+ in the +conf+ directory.

doc
~~~
Users should refer to documentation in +doc+ directory, which also contains +lyx+ files for potential publications from the analysis of bacterial transcriptome.

package
~~~~~~~
We use R-based analyses to postprocess the results from computationally intensive analyses, which are mostly done in *RNAseq Analysis*. Parts of the analyses can be incorporated in a manuscript for publication as a part of the result section.

pl
~~
Perl scripts.

run
~~~
It shows a menu of commands provided by *RNAseq Analysis*.

sh
~~
Bash scripts.

batch-qcalignde.sh
^^^^^^^^^^^^^^^^^^
This explains details of +run-qcalignde.sh+ batch script.
One job for a raw fastq file would be submitted to compute nodes. The job is
described in +batch-qcalignde.sh+ at the CAC working directory. After a job is
in queue and changes to a run state in a compute node, the job would copy data
files to the compute node. 
We copy Perl scripts of *RNA-seq Analysis*, and other binary executables to a
temporary directory of the compute node from the login node of the cluster: +pl+
directory of *RNA-seq Analysis*, +samtools+, and +bwa+. The compute node
would have a temporary directory, which is the actual working directory at a
compute node: _TMPDIR_ is the shell variable to the temporary directory. In
addition to stand-alone executables we need several shell and R script files. 
These include +job-fastq-qc+, +job-bwa-align+, +job-de+, and +job-de.R+.
Upto now we have copied stand-alone executables, and scripts.
Now we make directories at the compute node working directory, and copy small
and common data files from the head node to the the compute node. 
Three directories for species name "ua159" and repetition 1 are created at the
compute node working directory: shell variables _CDATADIR_, and _CBWADIR_.

----
CDATADIR=output/ua159/1/data
CBWADIR=output/ua159/1/bwa
----

Most of jobs are executed in shell function _process-data_ of
+batch-qcalignde.sh+. Quite often jobs can execute multiple instances of
executables depending on the number of CPUs available at the compute node.
Compute nodes at the CAC cluster had eight CPUs as of February 20th, 2012. 
The set of multiple instances may share a common resource that needs computation
prior to the stage of _process-data_. Examples include genome indexing stages
for short read alignment procedures. 

.Indexing genome files
----
./bwa index -p $CBWADIR/$GENOMEFASTA-bwa -a is \\
  $CDATADIR/$GENOMEFASTA
----

Let us turn to function _process-data_. We start with +job-fastq-qc+ shell
script, which takes a three-digit number as an argument.

.Execute a quality control 
----
bash job-fastq-qc 056 FASTQ056.fq.gz FASTQ056.prinseq.fq.gz 
----

In the +job-fastq-qc+ we take a raw fastq file to first remove adapter sequences
from the short reads in the fastq file, and to remove low quality 3' end parts.
In the +job-bwa-align+ we take the processed short reads to align them on a
reference genome.

.Align short reads using bwa and subread
----
bash job-bwa-align 056 FASTQ056.prinseq.fq.gz bwa/FASTQ056.sorted
----

In the third stage of +job-de+ we take the short read alignment files to count
short reads mapped on genes for summarizing numbers of reads see +job-de+,
+job-de.R+.

.Two pairs of input and output files of +job-de+ stage
----
output/ua159/1/bwa/FASTQ056.sorted.bam
output/ua159/1/bwa/FASTQ056.cl
----

Counting mapped short reads may require memory exceeding the capacity of a
compute node. So, we divide alignments smaller pieces, for each of which we
count reads, and then sum the counts.

species
~~~~~~~
Sample analysis files. This directory can be used for your analyses if _ROOTANALYSISDIR_ variable in +conf+ is set to the source code directory of *RNAseq Analysis*.

src
~~~
C, or C++ source codes.

ucsc
~~~~
Files for a UCSC genome browser.


Details and Future Development
------------------------------
You could read the details of implementation as a source code documentation. They may not make sense from the user perspective. Future developments include a pairwise comparison for determining differentially expressed genes, functional association of differentially expressed genes, transcript calls by applying a transcript caller such as ParseRNAseq, export of results (coverage) for showing them in UCSC genome tracks.

Useful Tools
~~~~~~~~~~~~
You could annotate bacterial genomes using xbase available at 
http://www.xbase.ac.uk/annotation.
You could compare two genomes to find genes unique to one of the two genome using genomeblast available at
http://bioinfo-srv1.awh.unomaha.edu/genomeblast/tutorial.php. Because genbank files created by +xbase+ were incompatible with the format required by genomeblast, we extract amino acid sequences from genbank file to find genes that are unique to one of the two genomes. A +bioperl+ script, +pl/extractcds.pl+ could be useful to extract protein sequences from a genbank file.

batch3.sh
~~~~~~~~~
Function _batch3-variable_ creates often-used shell variables.
_ROOTANALYSISDIR_ is set to a full file path by configuration.
_SPECIESFILE_ is the species file name relative to the directory where a +run+
is executed. _OUTPUTDIR_ is the output directory relative to _ROOTANALYSISDIR_. 
_BASEDIR_ is the species filenamed directory at _OUTPUTDIR_. _NUMBERDIR_ is a
directory 1 (repetition number) at _BASEDIR_. _DATADIR_ is placed at
_NUMBERDIR_. _BWADIR_ is also at _NUMBERDIR_, and so is _RUNANALYSIS_. Consider
that _DATADIR_ contains input files, _BWADIR_ contains processed files, and
_RUNANALYSIS_ contains output files. We have similar directory names in a remote
machine: _RBASEDIR_, _RNUMBERDIR_, _RDATADIR_, _RBWADIR_, and _RANALYSISDIR_.
We have similar directory names in a computing machine:
_CBASEDIR_, _CNUMBERDIR_, _CDATADIR_, _CBWADIR_, and _CANALYSISDIR_.

Function _batch3-output_ creates _DATADIR_, _BWADIR_, and _RUNANALYSIS_
directories.

Function _batch3-speciesfile_ creates shell variables set by _SPECIESFILE_.
_FASTQFILES_ is a list of numbers separated by spaces. _FASTQLABEL_ is a list of
sample names. _CACWORKDIR_ is the directory at which we submit jobs. 
_REFGENOMEFASTA_ and _REFGENOMETXDB_ are genbank and TranscriptDb files. They
should be at _ROOTANALYSISDIR_.  _QCALIGNDEWALLTIME_ is the limit of execution
time in hours.  _MINMAPQ_ is the minimum alignment mapping quality.
_MINTRIMQ_ is the minimum base quality to trim 3' end. 

Function _batch3-push-data_ help send files to the remote machine for job
submission by creating a shell script, +push-data.sh+. Execute the shell script
to send files for processing.

Function _batch3-get-data_ creates a shell script to get resulting files from
the remote machine. The files are +count.txt+, +count.multiple.txt+,
+qualPlot.pdf+, and +stat1.tex+.

Function _batch3-run-qcalignde_ creates most of shell and R scripts. 

File +run-qcalignde.sh+ is the main script to be executed when submitting jobs
to the cluster. It replaces a string named PBSARRAYSIZE with the number of FASTQ
files in +batch-qcalignde.sh+, and submit the batch file.

File +batch-qcalignde.sh+ is the batch script that is submitted to the cluster.
A function called +process-data+ in the batch script executes a series of jobs
for a FASTQ file. It first copies a FASTQ file from the remote data directory
called _RDATADIR_. We should find the FASTQ file in the remote data directory.
The file is copied to the parallel directory in the compute node, _CDATADIR_.
We use +job-stat+ to process the FASTQ file. 
We use +job-fastqc+ to remove parts of or whole short reads with low quality.
We use +job-bwa-align+ to align reads to a reference genome.
We use +job-de+ to count reads aligned to the reference genome.

Function _batch3-make-job_ creates all of the job files in shell and R scripts.
Bash script +job-stat+ takes a three-digit number, a gzipped FASTQ file name,
and an output RData file name.
Bash script +job-fastqc+ takes a three-digit number, a gzipped FASTQ file name,
and another gzipped FASTQ file name (output). 
Bash script +job-bwa-align+ takes a three-digit number (FASTQ ID), an input
gzipped FASTQ file name, and an output BAM file base name without the extension
of bam.
Bash script +job-de+ takes a sorted BAM file, the number of reads in the sorted
BAM file, and the number of reads in FASTQ file used as an input to bash script
+job-bwa-align+.
Bash scripts +job-simulate+ and +job-check+ create a small test data to check
the alignment and count procedure.

File +feature-txnc.txt+ contains R scripts to use the txdb file specified in a spceis file. This could be the key file for handling gene annotations. This file is added to R script files: +job-de.R+, +job-de-sum.R+, and +job-simulate.R+. We use R function _transcripts_ to extract regions, on which we count reads mapped. R function _cds_ extracts CDS regions. R package _GenomicFeatures_ features the two functions. I need a simple example files for handling R scripts. They are easy to use, and also easy to forget. Let's see what it does. We construct a transcript map with meta data. A transcript is of type being either "CDS" or "NOCDS." Regions not within the transcript map are of type being "NG." An R variable called _feature.txnc_ contains transcripts with 6 columns: seqnames, ranges, strand, tx_id, tx_name, and type. 

R script file +job-de.R+ takes takes a sorted BAM file, the number of reads in the sorted BAM file, and the number of reads in FASTQ file used as an input to bash script +job-bwa-align+. This is the same list of arguments as those of +job-de+. The first argument is used create the output file name by appending ".cl" to the sorted bam file. R package GenomicFeatures is used to extract annotation. The statistics of short reads are incomplete (FIXME). It bothers me that I did not have a complete information about statistics. R package GenomicRanges features summarizeOverlaps, which counts short reads mapped on amap of transcripts. _cl_ contains counts. _cl.nc_ is a subset of _cl_ for nongenic regions. _cl.multiple_ contains reads mapped on multiple places. _cl.multiple.nc_ is a subset of nongenic regions of _cl.multiple_. _cl.multiple.nocds_ is a subset of non-CDS regions of _cl.multiple_. The transcript map in txdb contains genes, non-genic "NG", and non-CDS "NOCDS". We have 4 values for the number of reads. _num.total.read_ is the number of total reads in the FASTQ file. We align _num.n.read_ reads on a reference genome. The bam file contains _num.mapped.read_ reads. Among them _num.unique.read_ reads are aligned with minimum quality score, _MINMAPQ_. _bv_ is an R _GappedAlignments_ object returned by R function _readBamGappedAlignments_ of package _Rsamtools_. _bv_ contains mapped reads with minimum of _MINMAPQ_ mapping quality score. _bv.multiple_ is an R _GappedAlignments_ object that contains mapped reads with mapping quality score less than _MINMAPQ_. We report overlapping genes. ``Now, I see a little bit what I did.'' 

R function _makeTranscriptDb_ requires a few R data frames in its arguments. An argument, transcripts, consists of transcript ID (integer), transcript name (character), chromosome name (character), strand ("+", "-"), start position (integer), end position (integer). A second argument, splicings, consists of transcript ID (integer A), exon ID (integer B), exon name (character), exon start and end (integers), cds start and end (integers). We create a txdb file based on the following rationale. An exon is a transcript. The exon or the transcript may contain a CDS. See the R script in _feature-txnc.txt_ how a txdb file is used.

Bash script +job-de-sum+ calls its R script. It passes _RBWADIR_ directory and a file that contains FASTQ IDs to the R script. R script file +job-de-sum.R+ takes a BWADIR directory, and a file containing FASTQ IDs. Use the ``cl'' files for the FASTQ IDs to create a table of counts. We create several _count.table_ R variables. +job-de.R+ creates _cl_, _cl.cds_, _cl.nocds_, _cl.tx_, and _cl.ng_. For these count variables, we have _count.table_, _count.table.cds_, _count.table.nocds_, and the like. This creates a number of files: 'count', 'count.cds', 'count.nocds', 'count.tx', and 'count.ng'. For multiple matched reads, we have 'count.m', 'count.m.cds', 'count.m.nocds', 'count.m.tx', and 'count.m.ng'. R script 'job-de-sum.R' also creates a table of statistics. Column +a+ is the number of reads in the FASTQ file. Column +b+ is the number of reads after quality control using PRINSEQ. Column +c+ is the number of reads in the sorted BAM file. Column +d+ is the number of counted reads multiply mapped on non-CDS transcripts. Column +e+ is the number of reads uniquely mapped. Column +e+ is the number of counted reads uniquely mapped on transcripts. Column +f+ is the number of counted reads uniquely mapped non-transcript regions.

Bash script +job-simulate+ creates test FASTQ files using txdb annotation. R script +job-simulate.R+ takes _FASTQNUM_ as the only argument.  Because we execute +job-simulate+ at the remote computer not at the compute node, we use _RBWADIR_ and _RDATADIR_ directories not _CBWADIR_ or _CDATADIR_. We use _feature.txnc_ or the complete feature to create short reads. We store sampled reads in _read.GA_. We sample reads from genes with 1,000 base pairs per chromosome. We use positions of reads to create a _GappedAlignments_ object and add it to _read.GA_. We use the positions to extract DNA sequences, and write them to a FASTQ file. Ignore warnings, which arise when adding _GappedAlignments_ with different chromosome configurations. 


cram
~~~~
Because short reads files tend to be large, it would be convenient to zip them
so that we can save storage and time of transfer. Although it is under
development, it seems to be a good idea to use a program called +cram+. Please,
make sure that you use the same version of the program in both zipping and
unzipping. You also need to make sure that you use the same reference genome.
Use the following command after executing +batch3+ menu.

.Cram short reads at _CACWORKDIR_
----
$ bash run-cram.sh
----

steps
~~~~~
The following scripts can be run separately in the cluster. They need
documentations.
I used to have separate scripts for quality control, alignment, and counting
reads. Although this was fine, it would produce unnecessary intermediate files
that could be very large. Because accumulated large files could be too big for
the compute node to host, this might cause problems in the pipeline. The
followings are descriptions for the separate analyses. They can be useful in
understanding separate analyses that are integrated in +run-qcalignde.sh+.

.To align reads step-by-step
----
$ bash run-fastqc.sh
$ bash run-cram.sh
$ bash run-cram2fastq.sh
$ bash run-bwa-align.sh
$ bash run-bias.sh
$ bash run-coverage.sh       <- takes time
$ bash run-coverage-pull.sh
$ bash run-parsernaseq.sh
$ bash run-ucsc.sh
$ bash run-de.sh -> not yet
----

.To create an input file for tux
----
$ bash job-coverage-start-end.sh
----
job files are supposed to be run in the compute node. Those with sh extension
would be run in the main node.

.To count reads
----
$ bash run-qcalignde.sh 
----
+run-qcalignde.sh+ includes fastqc, bwa-align, and de.

+run-fastqc.sh+ converts +data/FASTQ001.fq.gz+ to +bwa/FASTQ001.prinseq.fq.gz+.

+run-cram.sh+ converts +bwa/FASTQ001.prinseq.fq.gz+ to +bwa/FASTQ001.cram+.

+run-cram2fastq.sh+ converts +bwa/FASTQ001.cram+ to +bwa/FASTQ001.recovered.fq.gz+.

+job-stat+ converts +bwa/FASTQ001.fq.gz+ to +bwa/FASTQ001.fq.qualPlot.RData+.

+run-bwa-align.sh+ converts +bwa/FASTQ001.recovered.fq.gz+ to +bwa/FASTQ001.sorted.bam+.

+run-bias.sh+ converts +bwa/FASTQ001.sorted.bam+ to +bwa/FASTQ001.yml+.

+run-coverage.sh+ converts +bwa/FASTQ001.sorted.bam+ and +bwa/FASTQ001.yml+ to
+bwa/FASTQ001.cvg.*+.

+run-coverage-pull.sh+ converts +bwa/FASTQ001.cvg.*+ to +bwa/FASTQ001.coverage.RData+.
and +bwa/FASTQ001.wig+.

+run-fastqc.sh+ can use multiple CPUs by splitting FASTQ files, each of which is
processed by cutadapt and prinseq.

.To filter out the raw fastq files for quality control
----
bash job-fastqc 001 FASTQ001.fq.gz FASTQ001.prinseq.fq.gz 
----

.To align short reads on a reference genome
----
bash job-bwa-align 001 FASTQ001.prinseq.fq.gz FASTQ001.sorted 
----

+run-coverage.sh+ can use multiple nodes. BAM files are copied to each node
computer and copied again because readGappedAlignments(bamFile) R function
crashes when it tries to read a file from many computers.

+run-parsernaseq.sh+ creates +bwa/FASTQ001.parsernaseq+, +bwa/FASTQ001.bed2+ and 
+bwa/FASTQ001.operon+. 
File +bwa/FASTQ001.bed2+ is the ParseRNAseq output file in BED format.
File +bwa/FASTQ001.operon+ is another BED file of the transcript calls with
strand information inferred from genes annotations.

+run-ucsc.sh+ creates scripts and files to upload the genome browser.
----
$ bash job-ucsc-bed
----

+run-de.sh+ converts +bwa/FASTQ001.sorted.bam+ to +bwa/FASTQ001.sorted.bam.cl+.

Does +run-de.sh+ do this? We do not have that.

Randomly sample about 5 percent of the short reads.
awk 'BEGIN {srand()} !/^$/ {if (rand() <= .05 && NR%4==0) for ( o = 1; o <= 4; o++ ) {getline; print}}'

.Sample 0.1 percent of the total reads
----
fastq-sample.sh FASTQ056.fq.gz FASTQ056-0.001.fq.gz 0.001
----
