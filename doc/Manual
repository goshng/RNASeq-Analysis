User Manual of RNAseq Analysis
==============================
Sang Chul Choi <goshng@yahoo.co.kr>
v1.3, April 2012

Introduction
------------
Please, note that this is unfinished work. This manual changes as we add more
features to *RNAseq Analysis*.

A list of RNA-Seq data files are generated by sequencing bacterial
transcriptome.  Three steps should be performed before executing any menus
provided by *RNAseq Analysis*. Firstly, a proper configuration file needs to be
placed at +conf+ directory. See the section Configuration to setup your
configuration.  Secondly, the software packages specified in the configuration
file need to be installed. See the section Installation for what software
packages are needed.  Thirdly, a species file needs to be placed at +species+
directory, and the data files that are specified in the species file need to be
placed at proper places.  Refer to the section Species File below.  Now, you
are ready to start to analyze RNA-seq samples using *RNAseq Analysis*.

Execute the main menu using
----
$ ./run
----
First, call *init-file-system* to create directories for output files. Then,
call *choose-species* menu to create directories for your project.  The FASTQ
files must be gzipped files.  Try to call *batch2* and following the instruction
in the menu *batch2* below.

Quick Start
-----------

.Start of a project
. Create a conf/README file using conf/README.template
. Execute menu *init-file-system*

.Cram short reads
. Create a species file
. Execute menu *batch2*
. Run +output/your species name/push-data.sh+
. Go to _CACWORKDIR_, and run +run-cram.sh+

.Index a genome file for BWA alignment
. Create a species file
. Execute menu *choose-species*
. Execute menu *cp-genome* 
. Execute menu *bwa-index-genome*

.Align short reads to a reference genome
. Execute menu *bwa-index-genome*
. Execute menu *bwa-align*

.Create genome tracks for the mapped reads
. First align reads to a reference genome
. Execute menu *bwa-align*
. Execute menu *bwa-mpileup*

.Shorten reads
. Execute menu *bwa-sample*

IMPORTANT: The following needs attention.

.Create wigggle files with read lengths
. After the execution of menu *bwa-samtools-bed*
. Execute menu *bwa-samtools-wig*

.Outdated
. Execute menu *bwa-R-saveimage*
. Execute menu *bwa-danko-writewiggle* 

.Create a refFile of genome annotation.
.  Create a file with chrom, chromStart, chromEnd, name, and strand using a UCSC
genome browser or other method you would like. Note that you have to make sure
that genomic positions are 0-based or 1-based.
. Execute menu *bowtie-refflat*. The menu would create a file such as
output/smutans12/run-analysis/refFlat.txt.

.Compare two gene expression
. Use smutans R package.

Menus
-----

Menus are listed in order of frequent usages.

init-file-system
~~~~~~~~~~~~~~~~
This creates +output+ directory and others.

choose-species
~~~~~~~~~~~~~~
Create a file in +species+ directory before calling this menu. This command
creates output directories. Choose a species and a repetition number as you are
asked.  A directory named after the species file is created in the main +output+
directory: _BASEDIR_. Each species named directory can contain numbered
directories. The number corresponds to _REPETITION_ or repeated analyses under
the species named project. We would start with a number 1 for the first
repetition. In a number directory, you can have directories such as +data+,
+bwa+, +run-analysis+, etc. 

.Output directories
----
ROOTANALYSISDIR=[This is the directory where you execute menus]
OUTPUTDIR=$ROOTANALYSISDIR/output
BASEDIR=$OUTPUTDIR/$SPECIES
BASERUNANALYSIS=$BASEDIR/run-analysis
NUMBERDIR=$BASEDIR/$REPETITION
DATADIR=$NUMBERDIR/data
BWADIR=$NUMBERDIR/bwa
SUBREADDIR=$NUMBERDIR/subread
RUNANALYSIS=$NUMBERDIR/run-analysis
MAQDIR=$NUMBERDIR/maq
BOWTIEDIR=$NUMBERDIR/bowtie
TRANSCRIPTDIR=$NUMBERDIR/transcript
----

Output directories contains directories for species names in +species+
directory. A directory, e.g., +smutans+, contains one +run-analysis+ directory
and numbered directories. The directories with numbered names contains several
directories for analyses: +data+ would contain shared information such as genome
annotation, and +bwa+ would contains results from analyses using *BWA*. In the
BASH scripts I can access these directories using shell variables. See
+sh/global-variable.sh+ for details.

.Shell variables
----
SPECIES=smutans
BASERUNANALYSIS=output/smutans/run-analysis
REPETITION=1
DATADIR=output/smutans/1/data
BWADIR=output/smutans/1/bwa
----

batch2
~~~~~~
Menu *batch2* is developed and used with the 55 numbered RNA-seq data files
that are created by Mike Stanhope and Robert Burne labs.
We focus on finding differentially expressed
genes. In *batch2* menu I will refine the procedure developed in *batch* menu by
using more known tools or bioconductor R packages.
I will focus on the data quality control steps: removing low quality reads,
trimming low quality 3' end parts, timming parts of adapters, and the like. 

Because the SHELL scripts in *RNA-seq Analysis* create directories and save
output files in them, it is good to know what output directories are created. The
structure of output directories in the local machine where you execute the main
+run+ script is similar to that in the remote machine such as a cluster of
compute nodes. In the cluster, you will have a base directory where you would
submit jobs. This is called a working directory at the cluster, which can be
configured using _CACWORKDIR_ species variable.  In compute nodes, you will also
have base directories that are created in +/tmp+ directory. Under the +/tmp+
directory, you will have a temporary directory; e.g.,
+1209759-3.scheduler.v4linux+, which would be the base directory in a compute
node. Refer to menu *choose-species* for the directory structure in a base
direcotry.

Menu *batch2* creates a number of scripts at _BASEDIR_.  One of the SHELL
scripts, +push-data.sh+, is created at _BASEDIR_ by function _batch2-push-data_
in +sh/batch2.sh+.  The SHELL script copies input files including RNA-seq data
files. You might want to check the script to see what files are copied to the
cluster before executing it. I would copy large RNA-seq data files only once.
The script also creates data, bwa, and subread directory in the cluster.
It copies the reference genome, and the annotation file in gff format. It
copies another reference genome for unzipping short reads files.

.Copy data files to the cluster
----
$ bash output/ua159/push-data.sh
----

Wait! You might want to make sure whether the setup is finished before sending
files and submiting jobs.  We take two steps back before we submit jobs to get
the result. Firstly, let us go through what variables need to be set in the
species file. Secondly, you can use a test data set to check whether your
pipeline is working as expected. A check list for using this menu is as follows.
Note that we must have a single variable. Multiple instances of species file
variables would cause problems.

.Check the following spcies file variables
. fastq files
. adapter sequences
. quality score scheme
. cram data directory in _CRAMDIR_
. fastq file indices in _FASTQFILES_
. fastq file labels in _FASTQLABEL_
. cluster working directory in _CACWORKDIR_
. reference genome ID in _REFGENOMEID_
. reference genome fasta file in _REFGENOMEFASTA_
. reference genome annotation file in _REFGENOMEGFF_
. reference genome annotation TrancriptDb file in _REFGENOMETXDB_
. cram reference genome fasta file in _CRAMGENOMEFASTA_
. cram wall time in _CRAMWALLTIME_
. pipeline wall time in _QCALIGNDEWALLTIME_
. split file size limit in _MAXLINEDE_
. minimum alignment mapping quality in _MINMAPQ_
. set bwa options in _BWAOPTION_
. Rscript path in _CACRSCRIPT_
. set _SINGLECHROMOSOME_ to TRUE or FALSE
. set _TESTFASTQ_ to integers

.Four FASTQ files are created
----
TESTFASTQ:1 2 3 4
----

Set _SINGLECHROMOSOME_ to TRUE if you have a single chromosome, which is often
the case for bacterial genomes.

Because short reads files tend to be large, it would be convenient to zip them
so that we can save storage and time to transfer. Although it is under
development, it seems to be a good idea to use a program called cram. Please,
make sure that you use the same version of the program in both zipping and
unzipping. You also need to make sure that you use the same reference genome.

.Cram short reads
----
$ bash run-cram.sh
----

A simulation is not a sufficient way to check whether the pipeline of counting
short reads mapped on a reference genome is working properly. It could be a
neccessary condition. It also provides a way of debugging your scripts when
something does not work as expected.

.Species file variables for checking
----
FASTQFILES:57
TESTFASTQ:57
QUALITYSCORE057:sanger
ADAPTER057:GATCGGAAGAGCACACGTCTGAACTCCAGTCACCTTGTAATCTCGTATGCCGTCTTCTGCTTG
CRAMWALLTIME:1
QCALIGNDEWALLTIME:1
----

You might want to use a development queue. I set both of the wall time to 1 hour
to use a development queue. 

.To use a development queue
----
QUEUENAME:v4dev
----

.To align reads step-by-step
----
$ bash run-fastqc.sh
$ bash run-cram.sh
$ bash run-cram2fastq.sh
$ bash run-bwa-align.sh
----

.Execute scripts to check the simulation
----
$ bash job-simulate
$ bash run-fastqc.sh
$ bash run-cram.sh
$ bash run-qcalignde.sh
$ bash job-check
----

The last command, +job-check+, prints two numbers. Each number means the
proportion of genes with equal numbers of short reads mapped on a reference
genome from the simulation and one of two short read aligners, bwa or subread.
The number should be near 1. Often, they were larger than 0.9 but not 0.95. 
Once you are finished with simulation checks, change the type of queue in the
configuration file and wall time. Go through the check list above. Then, submit
the job.

.Time limit for a job of quality control, alignment, and counting short reads
----
QCALIGNDEWALLTIME:12
----

.To count short reads
----
$ bash run-qcalignde.sh
----

Once your jobs are finished, run the following command to create a count.txt
file.

.To summary counts in a count.txt
----
cac$ bash job-de-sum
----

Get count.txt files from the cluster.

.Get results from the cluster
----
$ bash output/ua159/get-data.sh
----

You will have two kinds of files for determining differentially expressed genes:
+count.txt+ and +count.txt.index+. You can use smutans R package to achieve
this. 

.Three files for differential expression study
----
output/ua159/1/bwa/count.txt
output/ua159/1/subread/count.txt
output/ua159/1/run-analysis/count.txt.index
----

Look at files in +package/smutans+ for seeing how to determine differentially
expressed genes. Espeically, see the tutorial of the package in 
+package/smutans/inst/doc/smutans.pdf+.

.R package smutans
----
package/smutans
package/smutans/R
package/smutans/inst/extdata
package/smutans/inst/doc/smutans.Rnw
----

I wished to answer to the question of fidning genes that are in smu21 but not in
ua159. In order to do that I need to first extract protein coding DNA sequences
from smu21 and ua159. Compare the two sets of gene sequences using BLAST. We
extract DNA sequences using parts of the R script in +job-simulate.R+. 

.To extract DNA sequences from the genome using gff annotation
----
cac$ bash job-extract
----

.Get results from the cluster
----
$ bash output/ua159/get-data.sh
----

I used to have separate scripts for quality control, alignment, and counting
reads. Although this was fine, it would produce unnecessary intermediate files
that could be very large. Because accumulated large files could be too big for
the compute node to host, this might cause problems in the pipeline. The
followings are descriptions for the separate analyses. They can be useful in
understanding separate analyses that are integrated in +run-qcalignde.sh+.

We start with a raw fastq file. Fastaq file numbers can be listed separated by
spaces in _FASTQFILES_.
Three variables are, for example, needed for one fastq file of index 56: _FASTQ056_
for the location of the file, _QUALITYSCORE056_ for quality score format, and 
_ADAPTER056_ for adapter sequence. 

.Fastq files in a species file
----
FASTQFILES:56 57
FASTQ056:R/x.fq.gz
QUALITYSCORE056:sanger
ADAPTER056:GATCGGAAGAGCACACGTCTGAACTCCAGTCACCTTGTAATCTCGTATGCCGTCTTCTGCTTG
----

I submit jobs using +run-qcalignde.sh+ at the CAC cluster. Users should have an
account at a linux cluster and specify a working directory for a species file.

.CAC workding directory in a species file
----
CACWORKDIR:run/rnaseq/021412
----

.Submit jobs for counting short reads mapped on genes
----
cac$ cd run/rnaseq/021412
cac$ bash run-qcalignde.sh
----
  
One job for a raw fastq file would be submitted to compute nodes. The job is
described in +batch-qcalignde.sh+ at the CAC working directory. After a job is
in queue and changes to a run state in a compute node, the job would copy data
files to the compute node. 
We copy PERL scripts of *RNA-seq Analysis*, and other binary executables to a
temporary directory of the compute node from the login node of the cluster: +pl+
directory of *RNA-seq Analysis*,
+samtools+, +bwa+, +subread-buildindex+, and +subread-align+. The compute node
would have a temporary directory, which is the actual working directory at a
compute node: _TMPDIR_ is the SHELL variable to the temporary directory. In
addition to stand-alone executables we need several SHELL and R script files. 
These include +job-fastq-qc+, +job-bwa-align+, +job-de+, +job-de2, +job-de.R,
and +job-de2.R+, and the like. Upto now we have copied stand-alone executables, and scripts.
Now we make directories at the compute node working directory, and copy small
and common data files from the head node to the the compute node. 
Three directories are created at the compute node working directory: SHELL
variables _CDATADIR_, _CBWADIR_, and _CSUBREADDIR_.

.Output directories at a compute working directory for species _ua159_, and repetition 1
----
CDATADIR=output/ua159/1/data
CBWADIR=output/ua159/1/bwa
CSUBREADDIR=output/ua159/1/subread
----

The genome and gff annotation files are specified in a species file.

.Genome and gff annotation files in a species file
----
REFGENOMEFASTA:/path/to/NC_004350.fna
REFGENOMEGFF:/path/to/NC_004350.gff
----

Most of jobs are executed in SHELL function _process-data_ of
+batch-qcalignde.sh+. Quite often jobs can execute multiple instances of
executables depending on the number of CPUs available at the compute node.
Compute nodes at the CAC cluster had eight CPUs as of February 20th, 2012. 
The set of multiple instances may share a common resource that needs computation
prior to the stage of _process-data_. Examples include genome indexing stages
for short read alignment procedures. 

.Indexing genome files
----
./bwa index -p $CBWADIR/$GENOMEFASTA-bwa -a is \\
  $CDATADIR/$GENOMEFASTA
./subread-buildindex -o \\
  $CSUBREADDIR/$GENOMEFASTA-subread \\
  $CDATADIR/$GENOMEFASTA
----

Let us turn to function _process-data_. We start with +job-fastq-qc+ SHELL
script, which takes a three-digit number as an argument.

.Unzip Execute a quality control 
----
bash job-cram2fastq 056 FASTQ056.cram FASTQ056.recovered.fq
gzip FASTQ056.recovered.fq
----

.Execute a quality control 
----
bash job-fastq-qc 056 FASTQ056.recovered.fq.gz FASTQ056.prinseq.fq.gz 
----

In the +job-fastq-qc+ we take a raw fastq file to first remove adapter sequences
from the short reads in the fastq file, and to remove low quality 3' end parts.
In the +job-bwa-align+ we take the processed short reads to align them on a
reference genome.

.Align short reads using bwa and subread
----
bash job-bwa-align 056 FASTQ056.prinseq.fq.gz bwa/FASTQ056.sorted subread/FASTQ056.sorted
----

In the third stage of +job-de+ we take the short read alignment files to count
short reads mapped on genes.

.Two pairs of input and output files of +job-de+ stage
----
output/ua159/1/bwa/FASTQ056.sorted.bam
output/ua159/1/subread/FASTQ056.sorted.bam
output/ua159/1/bwa/FASTQ056.cl
output/ua159/1/subread/FASTQ056.cl
----

Counting mapped short reads may require memory exceeding the capacity of a
compute node. So, we divide alignments smaller pieces, for each of which we
count reads, and then sum the counts. Script +job-de+ does the former and
another script +job-de2+ does the latter.  

.Maximum number of lines for a smaller alignment file
----
MAXLINEDE:5000000
CACRSCRIPT:/home/fs01/sc2265/Downloads/r-devel/b/bin/Rscript
----

Short reads mapped on a reference genome could be filtered out.

.Minimum mapping quality
----
MINMAPQ:30
----

.Maximum hours for zipping fastq files
----
CRAMWALLTIME:12
----
We use BWA to map reads for zipping them.

.Installed bwa and samtools
----
BWA:usr/bin/bwa-0.6.1
SAMTOOLS:usr/bin/samtools-0.1.18
PICARD:usr/bin/picard-tools-1.62
----
Download bwa and samtools at a directory in CAC cluster. Build and install them.
BWA's location would be $HOME/usr/bin/bwa-0.6.1.
Go to the working directory at your cluster, and execute +run-cram.sh+ script.

To change reference genomes replace the following three species file variables.

.Change reference genomes
----
REFGENOMEID:NC_004368
REFGENOMEFASTA:input/Streptococcus_agalactiae_NEM316/NC_004368.fna
REFGENOMEGFF:input/Streptococcus_agalactiae_NEM316/NC_004368.gff
----

batch
~~~~~
This manual is not yet written well. Until that happens, I just write down what
I am doing using *RNASeq Analysis*. Currently, I am analyzing the fourth set of
S. mutans RNA-seq data. The species file is +species/cornell+. Each species file
is created for each reference genome. The following variables in the species
should be set for a reference bacterial genome:
_REFGENOMEID_, _REFGENOMEGBK_, _REFGENOMEFASTA_, _REFGENOMEPTT_, and _REFGENOMEGFF_.
Full file paths for zipped FASTQ files should be given with FASTQ with three
digit numbers: e.g., _FASTQ001_. There are now 55 FASTQ files.
I wanted to analyze only some of them, and specified indices for the FASTQ files
using _FASTQFILES_ variable in the species file. I filtered out adapter
sequences from short reads. Each FASTQ file needs its adapter sequence to be
specified; the variable name is ADAPTER with three digits where the three digits
should be the same as the FASTQ file variable: e.g., _ADAPTER001_. Adapter
sequences can be found in the FASTQ file. Each short read comes with 6
nucleotides, which could be used to find adapter sequences. For some of them, I
asked people who sequenced them. After setting up reference genomes,
FASTQ files, and ADAPTER sequences, I used scripts in *RNASeq Analysis*. One of
the menu, *batch*, can be used for differential expression study. File
+sh/batch.sh+ should be edited before using it because the species name, and
repetition number are hard-coded in the file. After editing the file, run the
menu, *batch*. Then, use +push-data.sh+ to copy data to the cluster. Then, login
to the cluster and locate the working directory. The working directory should be
specified by species file variable _CACWORKDIR_. At the working directory, you would
find many scripts. Ideally, a single script file, +run.sh+, can do all of the
jobs for differential expression study work. 

.To run the batch job
----
$ bash run.sh &
----

.Problems
. feature-genome.out-geneonly is created by +pl/feature-genome.pl+ in
+run-de.sh+ that is one of created bash scripts by the menu *batch*. I had an
problem of chromsome name matching in +pl/de-count.pl+.
. File +pl/de-count.pl+ has an option singlegenome we might add this to the list
of options of the perl script. +run-de.sh+ should be edited. 


Many procedures are done in the cluster. I need a test procedure. 
I want to do the DE study for now.

.To install cutadapt in a linux cluster
----
python2.7 setup.py build_ext -i
python2.7 path/to/cutadapt --help
----

.Install these in the CAC working directory
----
bwa-0.5.9.tar.gz
cutadapt-1.0.tar.gz
samtools-0.1.16.tar.gz
----


fastq-sample
~~~~~~~~~~~~
Subsample the set of FASTQ files.
I subsample RNA-Seq short sequences. I can shorten RNA-Seq sequences.
I can keep reads with minimum lengths.


transcript-summary
~~~~~~~~~~~~~~~~~~
Transcripts are defined to be genomic features with constant expression. I use
RNA-Seq data to predict transcripts using either Martin's ParseRNAseq or Danko's
GROseq. I summarize the transcripts with known genes, small RNAs, and other
information.

How can I find the list of short reads that are not mapped? Use menu
*bwa-summary*. Use +pl/bwa-sam.pl+ with +unmapped+ command to create a FASTA
file with unmapped short reads.


FASTQ filtering
~~~~~~~~~~~~~~~
The raw FASTQ files needs proprocessing. I might change the name of this
procedure to *fastq-filter* because sampling short reads is one of two main
procedures in *fastq-sample*. 

Extract genome annotations
~~~~~~~~~~~~~~~~~~~~~~~~~~
You can extract bacterial genome annotations using *feature-genome* menu. To use
this menu identifier REFGENOMEPTT must be defined in the species file.
Downloaded bacterial genome directories from NCBI would contain a file with
+ptt+ extension.

.REFGENOMEPTT identifier in a species file
----
REFGENOMEPTT:bacteria/Streptococcus_mutans_UA159_uid57947/NC_004350.ptt
----

.Output files from genome annotations
----
$DATADIR/feature-genome.out-geneonly for protein coding genes
$DATADIR/feature-genome.out-intergenic for protein coding genes as well as intergenic regions
$DATADIR/feature-genome.out-intergeniconly for intergenic regions only
$DATADIR/feature-genome.out-startcodon for regions around start codons of genes
----

Extract DNA sequences using feature-genome
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
I can create a FASTA file of DNA sequences that are extracted from a reference
genome. Menu *extract-genome* is used to extract DNA sequences from a reference
genome using a BED file.

.FASTA files of extracted DNA sequences
----
$DATADIR/intergeniconly.fa is created using feature-genome.out-intergeniconly
----

BWA Alignment
~~~~~~~~~~~~~
Call *cp-genome* to copy the genome file in FASTA format to the data directory.
Call *bwa-index-genome* just right after *cp-genome* menu. 
Call *bwa-align* to produce the sorted alignment in BAM format.
Call *bwa-mpileup* to create pileup and wiggle files.

Now, call *fastq-summary* again to see the
proportions of short reads mapped on the reference genome.

Call *bwa-align*, *bwa-samse*, *bwa-samtools-view*, *bwa-samtools-sort*, and
*bwa-samtools-bed* menus in order. 
Menus from *bwa-align* to *bwa-samtools-bed* can be run in a single command
using *bwa-batch-align-to-bed*, which creates a +batch+ file at the base
directory. Just execute the +batch+ file with BASH shell.

.BWA alignment procedure
. +bwa index+ Index a reference genome
. +bwa aln+ Align short reads on the reference genome
. +bwa samse+ Convert SAI to SAM
. +samtools view -bS+ Convert SAM to BAM
. +samtools sort+ Sort BAM
. +samtools view+ Convert BAM to SAM

*bwa-align* produce the sorted alignment in BAM format. I do not use
*bwa-samse*, *bwa-samtools-view*, *bwa-samtools-sort*.

Call menu *bwa-mpileup* to create a pileup file, and to create a wiggle file to
upload RNA-Seq sample tracks. The species file should have READDEPTH, which is
used in +samtools mpileup+ -d option value. If the uploaded track is limited by
the value you specified, you should increase the value.
----
READDEPTH:300000
----

*bwa-summary* creates +sum.pos+ files. For example, +sum.pos+ files contains three
columns: short read names, start, and end positions of the short reads in the
reference sequence.
*bwa-summary* creates summary files: number of reads, number of reads uniquely
mapped. 
*bwa-summary* finds the total number of reads, the number of reads mapped.
A +sum+ file, e.g.,  output/omz/1/bwa/FASTQ01.sum, contains RNA-Seq short
sequence file, total number of the reads, and the number of short reads mapped.

DESeq
~~~~~
Prepare a +gene.pos+ file that contains gene name, chromosome, start, and end
position. Let's use ptt file for getting genes positions. What menu do I use?
Menu *feature-genome* could find genes.

The number of reads in a gene, or _read count_, is known to be somewhat linear
to the abundance of the RNA transcript of the gene. I wish to test whether an
observed difference in read counts for a gene is statistically significant. For
this test I need a model for the expected number of reads. For a set of given
genes with a range of lengths the read counts would be distributed. The number
of reads that are assigned to a gene is assumed to be distributed as a negative
binomial distribution with a mean and a variance.

*deseq* works with _omz_ species.

Prepare a file named +gene.pos+ with 4 columns of gene name, chromosome name,
gene start, and gene end. UCSC genome browser can be used to extract information
of known genes: go to Table menu at the top of the UCSC genome browser of
http://strep-genome.bscb.cornell.edu/, click Table menu, choose 
Group +Genes and Gene Prediction Tracks+, track +Known Genes+, and choose output
format +selected fields from primary and related tables+.

.A script to create gene.pos file from the table from the UCSC genome browser
----
awk '{ print $4 "\t" $1 "\t" $2 "\t" $3}' hgTables.ua159 > ../output/smutans12/1/data/gene.pos
----

.A script to create a count.txt for UA159 and TW1-Glucose, and TW1-Glucose and
TW1-Galactose
----
awk '{ print $1 "\t" $2 "\t" $12 }' count.txt > count-1-11.txt
awk '{ print $1 "\t" $12 "\t" $4 }' count.txt > count-11-3.txt
----

Given the count data we can proceed to compare gene expression.

.A gene.pos file
----
SMU109_00005    SMU109-OMZ175.contig1   44      283
----

Call *bwa-summary* to create +FASTQXX-sum.pos+ file.

Menu *bwa-pos2wig* creates a wiggle file from a pos file that is created by menu
*bwa-summary*. I want to use short reads with exact match to the reference
genome. I will use this short reads to call transcripts. The wiggle file can be
used to find regions with positive values as potential transcripts.

.A pos file 
----
shortReadIdentifier chr shortReadStart shortReadEnd flag mapQuality xt nm x0 x1 xm xo xg md
----

DEGseq
~~~~~~
DEGseq takes uniquely mapped reads from RNA-seq data with a gene annotation as input.
After menu *bwa-samtools-bed* is finished, you can execute *bwa-degseq-bed* to
create a bed for detecting genes differentially expressed using DEGseq. DEGseq
requires a refflat file. Call menu *bowtie-refflat* to create the file. You need
to prepare a _refFlat_ file to convert bowtie mapped reads to expression data
that DEGseq can process.  Create a file with chrom, chromStart, chromEnd, name,
and strand using a UCSC genome browser or other method you would like. Go to
strep-genome.bscb.cornell.edu.  Clock Tables. Select S. mutans UA159. Select
Genes and Gene Prediction Tracks. Select Known Genes.  choose output format
+selected fields from primary and related tables+.  Then, click get output
Choose chrom, chromStart, chromEnd, name, and strand.  Click get output.  Note
that you have to make sure that genomic positions are 0-based or 1-based.  .The
table should look like this
----
#chrom  chromStart      chromEnd        name    strand
chr1    193     1552    SMU_01  +
chr1    1707    2844    SMU_02  +
----
Menu *degseq* takes two RNA-Seq samples to compare gene expression level.
Menus *bowtie-refflat* and *bwa-samtools-bed* must be called before the call of
*degseq*. You need to decide which RNA-Seq samples are compared.

bwa-pos2wig
~~~~~~~~~~~
Where do I create an end.wig file, e.g., FASTQNUM-end.wig?

transcript-parsernaseq
~~~~~~~~~~~~~~~~~~~~~~
To fine a transcript map.

Configuration
-------------
File +conf/README.template+ can be used to create +conf/README+.
Add the following lines for your preferences.

.To execute jobs in your local machine
----
RUNMODE:local
----

.To execute jobs in a remote machine
----
RUNMODE:remote
----

Set more variables if you execute jobs in a remote machine. We let the remote
machine be CAC, which is one of the cornell linux clusters. We are not sure what
other linux cluster options are available. If your cluster system is different
from one in CAC, you have to modify parts of the cluster job submission in SHELL
scripts. You are recommended to set up ssh login without password because we
need log in the remote machine to create directories and copy files back and
forth. See 
http://www.linuxproblem.org/art_9.html
or
http://smbjorklund.no/ssh-login-without-password-using-os-x.

.User ID and login address
----
CAC_USERNAME:sc2265
CAC_LOGIN:linuxlogin.cac.cornell.edu
----

Set the _CAC_LOGIN_ variable even if you execute jobs in your local machine.
This is a trick. Otherwise, we have to replace all of the commands for a remote
machine with those of the commands for a local machine.

.User ID and login address
----
CAC_LOGIN:localhost
----

We used to have _CAC_ROOT_ as a directory for saving scripts and input/output
files. Now, we have two separate directories for saving and running scripts in
a remote machine, and for saving input/output files. We do not use _CAC_ROOT_
variable any more. 

----
CAC_ROOT:Documents/Projects/rnaseq
----

Shell scripts are copied to a directory. _CACWORKDIR_ variable is species file
variable not conf variable.

.Scripts directory
----
CACWORKDIR:run/rnaseq/040812
----

Create the working directory.

----
pbs$ mkdir -p $HOME/run/rnaseq/040812
----

While running jobs, input and output files are stored in _ROUTPUTDIR_ directory.
When jobs are finished, files can be copied to the output directory of the base
directory in your local machine. This may be confusing, but convenient because
we can easily delete _ROUTPUTDIR_ directory when we do not need it. We would
want to save files in the output directory in your local machine.

.Input and output directories
----
ROUTPUTDIR:/Users/goshng/Documents/Projects/RNASeq-Analysis/routput
----

----
pbs$ mkdir -p /Users/goshng/Documents/Projects/RNASeq-Analysis/routput
----

If the remote machine is a linux cluster such as PBS, one may need config the
batch system. The CAC cluster requires access identifier and queue name.

.To execute jobs in a linux cluster machine
----
RUNMODE:pbs
----

.Batch system configuration
----
BATCHEMAIL:schoi@cornell.edu
BATCHACCESS:acs4_0001
QUEUENAME:v4
----

Installation
------------
Software packages are employed for the analysis. These should be installed on
the local or remote machine. First, create directories called +downloads+ and
+build+. If you use your local machine, follow this instruction in your machine.
You have to log in your remote machine if you use other machine such as a linux
cluster.

----
$ mkdir -p downloads/build
----

Create a +bin+ directory to save executable files.

----
$ mkdir -p $HOME/usr/bin
----

BWA
~~~
Dowanload BWA source code available at http://bio-bwa.sourceforge.net. 

----
$ downloads/bwa-0.6.1.tar.bz2
----

Extract the file and compile it.

----
$ cd downloads/build
$ tar jxf ../bwa-0.6.1.tar.bz2
$ cd bwa-0.6.1; make; cd ..
$ mv bwa-0.6.1 $HOME/usr/bin
----

Edit +conf/README+ if necessary; Add the following line. The base directory is
$HOME or your home directory. Shell variable $BWA is replaced by
+/home/userid/usr/bin/bwa-0.6.1/bwa+.

----
BWA:usr/bin/bwa-0.6.1/bwa
----

SAMTools
~~~~~~~~
Download SAMtools available at http://samtools.sourceforge.net.

----
$ downloads/samtools-0.1.18.tar.bz2
----

Extract the file and compile it.

----
$ cd downloads/build
$ tar jxf ../samtools-0.1.18.tar.bz2
$ cd samtools-0.1.18; make; cd ..
$ mv samtools-0.1.18 $HOME/usr/bin
----

Edit +conf/README+ if necessary; Add the following line. The base directory is
$HOME or your home directory. Shell variable $SAMTOOLS is replaced by
+/home/userid/usr/bin/samtools-0.1.18/samtools+.

----
SAMTOOLS:usr/bin/samtools-0.1.18/samtools
----

subread
~~~~~~~
Download subread available at http://subread.sourceforge.net. 
Another short read aligner. This is used in menu *batch2*.
As of April 2012, it did not support Mac OS X. Authors said that they would make
a Mac OS X version available in 2012.

prinseq
~~~~~~~
Download a prinseq lite version available at http://prinseq.sourceforge.net.
Extract the file and move the directory.

----
$ cd downloads/build
$ tar zxf ../prinseq-lite-0.17.4.tar.gz
$ mv prinseq-lite-0.17.4 $HOME/usr/bin
----

Edit +conf/README+ if necessary; Add the following line. The base directory is
$HOME or your home directory. Shell variable $PRINSEQ is replaced by
+/home/userid/usr/bin/prinseq-lite-0.17.4/prinseq-lite.pl+.

----
PRINSEQ:usr/bin/prinseq-lite-0.17.4/prinseq-lite.pl
----

Picard
~~~~~~
Download Picard available at http://picard.sourceforge.net. Unzip the file and
move directories.

----
$ cd downloads/build
$ unzip ../picard-tools-1.65.zip
$ mv picard-tools-1.65 $HOME/usr/bin
$ mv snappy-java-1.0.3-rc3.jar $HOME/usr/bin
----

Edit +conf/README+ if necessary; Add the following line. The base directory is
$HOME or your home directory. Shell variable $PICARD is replaced by
+/home/userid/usr/bin/picard-tools-1.65+.

----
PICARD:usr/bin/picard-tools-1.65
----

CRAM Toolkit
~~~~~~~~~~~~
Download CRAM Toolkit available at http://www.ebi.ac.uk/ena/about/cram_toolkit.
Move the file to +$HOME/usr/bin+.

----
$ cd downloads/build
$ mv ../cramtools.jar $HOME/usr/bin
----

Edit +conf/README+ if necessary; Add the following line. The base directory is
$HOME or your home directory. Shell variable $CRAMTOOLS is replaced by
+/home/userid/usr/bin/cramtools.jar+.

----
CRAMTOOLS:usr/bin/cramtools.jar
----

cutadapt
~~~~~~~~
Download cutadapt available at http://code.google.com/p/cutadapt.

----
$ cd downloads/build
$ tar zxf ../cutadapt-1.0.tar.gz 
$ mv cutadapt-1.0 $HOME/usr/bin
----

Edit +conf/README+ if necessary; Add the following line. The base directory is
$HOME or your home directory. Note that _CUTADAPT_ must be the absolute path of
the binary executable. We would call python with the executable. Do not use a
relative file path.

----
CUTADAPT:/home/user/usr/bin/cutadapt-1.0/cutadapt
----

NOTE:The following prorams need to be checked. I have not yet time to edit the
following description of the installation.

----
$ python setup.py build
$ sudo python setup.py install
CUTADAPT:/usr/local/bin/cutadapt
----

python
~~~~~~
Set _PYTHON_ variable to a file.

----
PYTHON:/opt/epd/bin/python2.7
----

Rscript
~~~~~~~
Set _CACRSCRIPT_ variable.

----
CACRSCRIPT:/home/fs01/sc2265/Downloads/r-devel/b/bin/Rscript
----

BOWTIE
~~~~~~
Download BOWTIE and install it under +src+ directory. The following command
should print a help message from it. Edit +conf/README+ if necessary.
----
$ src/bowtie-0.12.7/bowtie
----


segemehl
~~~~~~~~
Download segemehl at http://www.bioinf.uni-leipzig.de/Software/segemehl. You
could compile the source in this repository of rnaseq-analysis.
http://www.bioinf.uni-leipzig.de/Software/segemehl/
----
$ cd src/segemehl_0_0_9_4
$ make
----

FASTAX-Toolkit
~~~~~~~~~~~~~~
Download FASTAX-Toolkit at
http://hannonlab.cshl.edu/fastx_toolkit/fastx_toolkit-0.0.13.tar.bz2
and 
http://hannonlab.cshl.edu/fastx_toolkit/libgtextutils-0.6.tar.bz2.

edgeR
~~~~~
In R, run the two lines of
----
source("http://www.bioconductor.org/biocLite.R")
biocLite("edgeR")
----

DEGseq
~~~~~~
In R, run the two lines of
----
source("http://www.bioconductor.org/biocLite.R")
biocLite("DEGseq")
----

TopHat
~~~~~~
Download the Mac OS X x86_64 binary from http://tophat.cbcb.umd.edu[here].
Untar it and add the directory to PATH so that I can run it without full path.

Cufflinks
~~~~~~~~~
Download the Mac OS X x86_64 binary from http://cufflinks.cbcb.umd.edu[here].
Untar it and add the directory to PATH so that I can run it without full path

ncbi-blast
~~~~~~~~~~

ftp://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/LATEST/ 
ncbi-blast-2.2.25+-x64-linux.tar.gz
is used in the cluster.

MUSCLE
~~~~~~

http://www.drive5.com/muscle/downloads3.8.31/muscle3.8.31_i86linux64.tar.gz

.Create a +build+ directory at the base directory +run/rnaseq/110111+ of a cluster.
----
cac:run/rnaseq/110111/build/muscle3.8.31_i86linux64  
cac:run/rnaseq/110111/build/ncbi-blast-2.2.25+
cac:run/rnaseq/110111/build/RNAz-2.1
----

RNAz
~~~~
http://www.tbi.univie.ac.at/~wash/RNAz/

----
wget http://www.tbi.univie.ac.at/~wash/RNAz/RNAz-2.1.tar.gz
wget http://www.tbi.univie.ac.at/RNA/ViennaRNA-1.8.5.tar.gz
----

In the CAC:
----
mkdir b
cd b
../configure --prefix=$HOME/usr 
----

uniprot90
~~~~~~~~~
wget ftp://ftp.uniprot.org/pub/databases/uniprot/uniref/uniref90/uniref90.fasta

RNAplex
~~~~~~~
http://www.bioinf.uni-leipzig.de/Software/RNAplex/

RNAz
~~~~
https://github.com/wash/rnaz

Vienna RNA Package
~~~~~~~~~~~~~~~~~~
http://www.tbi.univie.ac.at/~ivo/RNA/RNAplfold.html

Species File
------------
A setup for *RNAseq Analysis* is described in a species file in +species+
directory. Variables are set by a variable name and its value separated by a
colon.

.Variable in a species file
----
variable:value
----

Place fastq files in your file system or somewhere in the computer. Then,
specify locations of the fastq files. Variables are prefixed _FASTQ_ with
three-digit numbers with zeros prepended. Currently, the file extension must be
fq and files must be zipped using +gzip+. So, files should end with +fq.gz+.

.fastq files
----
FASTQ001:/path/to/file1.fq.gz
FASTQ002:/path/to/file2.fq.gz
----

You may wish to process all of fastq files, or some of them. Specify which fastq
files you wish to use using _FASTQFILES_ variable. Use _FASTQLABEL_ to group
different fastq files. Labels are used for the purpose of differential
expression study. They are saved in a file called +count.txt.index+.

.File indices for fastQ files
----
FASTQFILES:1 2
FASTQLABEL:UA159 TW1
----

Quality scores can be phred33 or phred64. Use a value of illumina for phred64,
and a value of sanger for phred33.  Variables are prefixed _QUALITYSCORE_ with
three-digit numbers with zeros prepended. Because each fastq file has a
distinct quality score scheme, you need to specify quality score schemes as many
as fastq files.

.Quality scores schemes
----
QUALITYSCORE001:illumina
QUALITYSCORE002:sanger
----

Each fastq file is associated with an Illumina adapter sequence. They must be
specified, and are used to remove adapter sequences in short reads.  Variables
are prefixed _ADAPTER_ with three-digit numbers with zeros prepended. 

.Adapter sequences
----
ADAPTER001:GATCGGAAGAGCACACGTCTGAACTCCAGTCACCGATGTATCTCGTATGCCGTCTTCTGCTTG
ADAPTER002:GATCGGAAGAGCACACGTCTGAACTCCAGTCACTGACCAATCTCGTATGCCGTCTTCTGCTTG
----

After creating all of the scripts in your local machine, you would submit jobs
at a directory in the cluster. You need to create the directory while you
prepare a *RNASeq Analysis* by editing a species file.

.Cluster working directory
----
CACWORKDIR:run/rnaseq/022712
----

.Create the working directory
----
cac> mkdir -p run/rnaseq/022712
----

To map short reads on a reference genome, you must specify the file paths of
reference genome files and gene annotations.

.Reference genomes
----
REFGENOMEFASTA:path/to/NC_004350.fna
REFGENOMEGFF:path/to/NC_004350.gff
----


SHELL variables
---------------
The directory +sh+ contains a number of BASH SHELL scripts. I describe some of
SHELL often-used variables.

.fastQ file name variable
----
FASTQNUM=FASTQ$(printf "%03d" $g)
----
Files
-----
Input and output files are created in *RNASeq Analysis*. 

feature-genome.out-intergeniconly
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
A BED-format file contains intergenic regions of a reference genome.

.feature-genome.out-geneonly
----
chr1  193 1552  SMU.01  0 +
----

Scripts
~~~~~~~

.Subtract B from A where A and B are single-column number files
----
bash colsubtract.sh A B > C
----

TODO
----

This is by no means a final version of *RNAseq Analysis*, and it keeps evolving
as we need works to do. I write down things that would need attention later.

