User Manual of RNAseq Analysis
==============================
Sang Chul Choi <goshng@yahoo.co.kr>
v1.5, June 2012

UNFINISHED

Introduction
------------
A list of RNA-Seq data files are generated by sequencing bacterial
transcriptome.  Three steps should be performed before executing menus
provided by *RNAseq Analysis*. Firstly, a proper configuration file needs to be
placed at +conf+ directory. See the section <<Configuration>> to setup your
configuration.  Secondly, the software packages specified in the configuration
file need to be installed. See the section <<Installation>> for what software
packages are needed.  Thirdly, a species file needs to be placed at +species+
directory, and the data files that are specified in the species file need to be
placed at proper places.  Refer to the section <<SpeciesFile,Species File>>
below.  Now, you are ready to start to analyze RNA-seq samples using *RNAseq
Analysis*.

.Execute the main menu 
----
$ ./run
----
First, call *init-file-system* to create directories for output files. Then,
call *choose-species* menu to create directories for your project.  
Select *batch2* and following the instruction in the menu *batch2* below.

Quick Start
-----------
.Start of a project
. Create a conf/README file using conf/README.template
. Execute menu *init-file-system*

.Create a species file
. Execute menu *choose-species*

.Prepare a genome annotation file
. Download the gff file of the chosen species
. Edit the gff file so that the chromosome name is simply chr1, chr2, etc.
. Execute menu *convert-gff2txdb*
. Use the txdb file in subsequent analysis

.Batch2
. Create a species file
. Execute menu *batch2*
. Run +output/your species name/push-data.sh+
. Go to _CACWORKDIR_, and run +run-qcalignde.sh+
. Run +job-de-sum+ at _CACWORKDIR_
. Run +job-stat-plot+ at _CACWORKDIR_
. Run +output/your species name/get-data.sh+

.Check quality of short reads
. Execute menu *batch2*
. Run +run-fastqc.sh+ at _CACWORKDIR_
. Run +job-stat-plot+ at _CACWORKDIR_
. Run +output/your species name/get-data.sh+

.Test short reads alignment
. Execute menu *batch2*
. Run +job-simulate+ at _CACWORKDIR_ 
. Run +run-qcalignde.sh+ at _CACWORKDIR_
. Run +job-check+ at _CACWORKDIR_ 

.Compare two gene expression
. Use smutans R package.

.Create a tux input file
. Run +run-tux.sh+ at _CACWORKDIR_
. Run +job-tux-sum+ at _CACWORKDIR_
. Run +output/your species name/get-data.sh+
. Check +tux.in+ file
. Check also +R/tux.R+ to find size factors and two alphas.

Menus
-----
*RNAseq Analysis* menus provide users with access to commands for analyzing
bacterial RNA-seq data.

init-file-system
~~~~~~~~~~~~~~~~
This creates +output+ directory. Because the output directory can be large, a
separate hard drive can be mounted and used by symbolic links. Users might want
to create +data+, and +downloads+ directories. The +data+ can be used to store
raw data files including FASTQ, genome, and genome annotation files. The
+downloads+ directory can be used to store other software packages for
installation.

choose-species
~~~~~~~~~~~~~~
Create a file in +species+ directory before calling this menu.  Refer to the
section <<SpeciesFile,Species File>>. It creates output directories under the
species name subdirectory in +species+ directory. Choose a species and a
repetition number as you are asked. Note that we use the following output
directory structure. We use the same output structures in the compute node by
prefixing _C_, and in the remote machine by prefixing _R_. For example,
_CDATADIR_ is similar to _DATADIR_ except _OUTPUTDIR_ being just +output+.
_RDATADIR_ is different from _DATADIR_ in that _OUTPUTDIR_ is replaced by
_ROUTPUTDIR_, which is set in +conf/README+.

anchor:ShellVariable[]

.Output directories
----
SPECIES=[Your species name without spaces]
ROOTANALYSISDIR=[This is the directory where you execute menus]
OUTPUTDIR=$ROOTANALYSISDIR/output
BASEDIR=$OUTPUTDIR/$SPECIES
BASERUNANALYSIS=$BASEDIR/run-analysis
NUMBERDIR=$BASEDIR/$REPETITION
DATADIR=$NUMBERDIR/data
BWADIR=$NUMBERDIR/bwa
RUNANALYSIS=$NUMBERDIR/run-analysis
TRANSCRIPTDIR=$NUMBERDIR/transcript
----
This menu starts to create a directory named after the species file is created
in the main +output+ directory: _BASEDIR_. Each species named directory can
contain numbered directories. The number corresponds to _REPETITION_ or repeated
analyses under the species named project. We would start with a number 1 for the
first repetition. In a number directory, you can have directories such as
+data+, +bwa+, +run-analysis+, etc.  The +bwa+ directory would contains results
from analyses using *BWA*. In the BASH scripts I can access these directories
using shell variables. See +sh/global-variable.sh+ for details.

txdb
~~~~
We need an annotation file for differential expression study. We 
create a txdb file using a gff or a BED file. See menu *convert-gff2txdb* or
*convert-bed2txdb*.  Because we assume chromosome names to be chr1, chr2, etc,
edit the gff file so that the chromosome name is chr1 for a single chromosome
bacterial genome. Bacterial genomes with multiple chromosomes should have
chr1, chr2, etc.

feature-genome
~~~~~~~~~~~~~~
You could extract bacterial genome annotations using *feature-genome* menu. To
use this menu identifier REFGENOMEPTT must be defined in the species file.
Downloaded bacterial genome directories from NCBI would contain a file with
+ptt+ extension.

----
REFGENOMEPTT:path/to/NC_004350.ptt
----

Output files from genome annotations include the following files.

----
$DATADIR/feature-genome.out-geneonly for protein coding genes
$DATADIR/feature-genome.out-intergenic for protein coding genes as well as intergenic regions
$DATADIR/feature-genome.out-intergeniconly for intergenic regions only
$DATADIR/feature-genome.out-startcodon for regions around start codons of genes
----

Extract DNA sequences using feature-genome.
I can create a FASTA file of DNA sequences that are extracted from a reference
genome. Menu *extract-genome* is used to extract DNA sequences from a reference
genome using a BED file.

FASTA files of extracted DNA sequences.

----
$DATADIR/intergeniconly.fa is created using feature-genome.out-intergeniconly
----

batch2
~~~~~~
Menu *batch2* is developed and used with the 55 numbered RNA-seq data files
that are created by Mike Stanhope and Robert Burne labs.
We focus on finding differentially expressed
genes. In *batch2* menu I will refine the procedure developed in *batch* menu by
using more known tools or bioconductor R packages.
I will focus on the data quality control steps: removing low quality reads,
trimming low quality 3' end parts, timming parts of adapters, and the like. 

Because the SHELL scripts in *RNA-seq Analysis* create directories and save
output files in them, it is good to know what output directories are created. The
structure of output directories in the local machine where you execute the main
+run+ script is similar to that in the remote machine such as a cluster of
compute nodes. In the cluster, you will have a base directory where you would
submit jobs. This is called a working directory at the cluster, which can be
configured using _CACWORKDIR_ species variable.  In compute nodes, you will also
have base directories that are created in +/tmp+ directory. Under the +/tmp+
directory, you will have a temporary directory; e.g.,
+1209759-3.scheduler.v4linux+, which would be the base directory in a compute
node. Refer to menu *choose-species* for the directory structure in a base
direcotry.

Menu *batch2* creates a number of scripts at _BASEDIR_ 
(See <<ShellVariable,Output directories>>).  One of the SHELL
scripts, +push-data.sh+, is created at _BASEDIR_ by function _batch2-push-data_
in +sh/batch2.sh+.  The SHELL script copies input files including RNA-seq data
files. You might want to check the script to see what files are copied to the
cluster before executing it. I would copy large RNA-seq data files only once.
The script also creates data, bwa, and subread directories in the cluster.
It copies the reference genome, and the annotation file in gff format. It
copies another reference genome for uncramming short reads files. 

.Copy data files to the cluster
----
$ bash output/ua159/push-data.sh
----

Put this in somewhere else even before *batch2* menu.
Note: we need an annotation file for differential expression study. We 
create a txdb file using a gff or a BED file. See menu *convert-gff2txdb* or
*convert-bed2txdb*.

.To create txdb from gff
----
Edit NC_004350.fna and NC_004350.gff so that the chromosome name is chr1.
Rscript R/gff2txdb.R
----

Wait! You might want to make sure whether the setup is finished before sending
files and submiting jobs.  We take two steps back before we submit jobs to get
the result. Firstly, go through what variables need to be set in the
species file (see section <<SpeciesFile,Species File>>).
Secondly, you can use a test data set to check whether your
pipeline is working as expected. To test the pipeline set 
_FASTQFILES_ and _TESTFASTQ_ in the species file

----
FASTQFILES:101 102
TESTFASTQ:101 102
QUALITYSCORE101:sanger
QUALITYSCORE102:sanger
ADAPTER101:GATCGGAAGAGCACACGTCTGAACTCCAGTCACCTTGTAATCTCGTATGCCGTCTTCTGCTTG
ADAPTER102:GATCGGAAGAGCACACGTCTGAACTCCAGTCACCTTGTAATCTCGTATGCCGTCTTCTGCTTG
QCALIGNDEWALLTIME:1
----

A simulation is not a sufficient way to check whether the pipeline of counting
short reads mapped on a reference genome is working properly. It is a
necessary condition. It also provides a way of debugging your scripts when
something does not work as expected.
You might want to use a development queue. I set both of the wall time to 1 hour
to use a development queue by editting +conf/README+. 

----
QUEUENAME:v4dev
----

Use the following commands at _CACWORKDIR_.

----
$ bash job-simulate
$ bash run-qcalignde.sh
$ bash job-check
----

The last command, +job-check+, prints two numbers. Each number means the
proportion of genes with equal numbers of short reads mapped on a reference
genome from the simulation and one of two short read aligners, bwa or subread.
The number should be near 1. Often, they were larger than 0.9 but not 0.95. 
Once you are finished with simulation checks, change the type of queue in the
configuration file, and wall time _QCALIGNDEWALLTIME_ in the species file. 
Go through the check list above. Then, submit the job at _CACWORKDIR_.

----
cac$ bash run-qcalignde.sh
----

Once your jobs are finished, run the following command to create a count.txt
file.

----
cac$ bash job-de-sum
----

You can also create base quality scores of short reads before and after trimming
3' end of short reads.

----
cac$ bash job-stat-plot
----

Get count.txt files from the cluster.

----
$ bash output/ua159/get-data.sh
----

You will have two kinds of files for determining differentially expressed genes:
+count.txt+ and +count.txt.index+. You can use smutans R package to achieve
this. 

----
output/ua159/1/bwa/count.txt
output/ua159/1/run-analysis/count.txt.index
----

count-cds
~~~~~~~~~
Menu *count-cds* extracts CDS genes from +count.txt+.

deseq
~~~~~
We need a example run of DESeq by just comparing two conditions, which would be
mostly often used.

Look at files in +package/smutans+ for seeing how to determine differentially
expressed genes. Espeically, see the tutorial of the package in 
+package/smutans/inst/doc/smutans.pdf+.

.R package smutans
----
package/smutans
package/smutans/R
package/smutans/inst/extdata
package/smutans/inst/doc/smutans.Rnw
----

Prepare a +gene.pos+ file that contains gene name, chromosome, start, and end
position. Let's use ptt file for getting genes positions. What menu do I use?
Menu *feature-genome* could find genes.

The number of reads in a gene, or _read count_, is known to be somewhat linear
to the abundance of the RNA transcript of the gene. I wish to test whether an
observed difference in read counts for a gene is statistically significant. For
this test I need a model for the expected number of reads. For a set of given
genes with a range of lengths the read counts would be distributed. The number
of reads that are assigned to a gene is assumed to be distributed as a negative
binomial distribution with a mean and a variance.

*deseq* works with _omz_ species.

Prepare a file named +gene.pos+ with 4 columns of gene name, chromosome name,
gene start, and gene end. UCSC genome browser can be used to extract information
of known genes: go to Table menu at the top of the UCSC genome browser of
http://strep-genome.bscb.cornell.edu/, click Table menu, choose 
Group +Genes and Gene Prediction Tracks+, track +Known Genes+, and choose output
format +selected fields from primary and related tables+.

.A script to create gene.pos file from the table from the UCSC genome browser
----
awk '{ print $4 "\t" $1 "\t" $2 "\t" $3}' hgTables.ua159 > ../output/smutans12/1/data/gene.pos
----

.A script to create a count.txt for UA159 and TW1-Glucose, and TW1-Glucose and
TW1-Galactose
----
awk '{ print $1 "\t" $2 "\t" $12 }' count.txt > count-1-11.txt
awk '{ print $1 "\t" $12 "\t" $4 }' count.txt > count-11-3.txt
----

Given the count data we can proceed to compare gene expression.

.A gene.pos file
----
SMU109_00005    SMU109-OMZ175.contig1   44      283
----

Call *bwa-summary* to create +FASTQXX-sum.pos+ file.

Menu *bwa-pos2wig* creates a wiggle file from a pos file that is created by menu
*bwa-summary*. I want to use short reads with exact match to the reference
genome. I will use this short reads to call transcripts. The wiggle file can be
used to find regions with positive values as potential transcripts.

.A pos file 
----
shortReadIdentifier chr shortReadStart shortReadEnd flag mapQuality xt nm x0 x1 xm xo xg md
----

batch-qcalignde.sh
~~~~~~~~~~~~~~~~~~
This explains details of +run-qcalignde.sh+ batch script.
One job for a raw fastq file would be submitted to compute nodes. The job is
described in +batch-qcalignde.sh+ at the CAC working directory. After a job is
in queue and changes to a run state in a compute node, the job would copy data
files to the compute node. 
We copy PERL scripts of *RNA-seq Analysis*, and other binary executables to a
temporary directory of the compute node from the login node of the cluster: +pl+
directory of *RNA-seq Analysis*,
+samtools+, +bwa+, +subread-buildindex+, and +subread-align+. The compute node
would have a temporary directory, which is the actual working directory at a
compute node: _TMPDIR_ is the SHELL variable to the temporary directory. In
addition to stand-alone executables we need several SHELL and R script files. 
These include +job-fastq-qc+, +job-bwa-align+, +job-de+, +job-de2, +job-de.R+,
and +job-de2.R+, and the like. Upto now we have copied stand-alone executables, and scripts.
Now we make directories at the compute node working directory, and copy small
and common data files from the head node to the the compute node. 
Three directories for species name "ua159" and repetition 1 are created at the
compute node working directory: SHELL variables _CDATADIR_, _CBWADIR_, and
_CSUBREADDIR_.

----
CDATADIR=output/ua159/1/data
CBWADIR=output/ua159/1/bwa
CSUBREADDIR=output/ua159/1/subread
----

Most of jobs are executed in SHELL function _process-data_ of
+batch-qcalignde.sh+. Quite often jobs can execute multiple instances of
executables depending on the number of CPUs available at the compute node.
Compute nodes at the CAC cluster had eight CPUs as of February 20th, 2012. 
The set of multiple instances may share a common resource that needs computation
prior to the stage of _process-data_. Examples include genome indexing stages
for short read alignment procedures. 

.Indexing genome files
----
./bwa index -p $CBWADIR/$GENOMEFASTA-bwa -a is \\
  $CDATADIR/$GENOMEFASTA
./subread-buildindex -o \\
  $CSUBREADDIR/$GENOMEFASTA-subread \\
  $CDATADIR/$GENOMEFASTA
----

Let us turn to function _process-data_. We start with +job-fastq-qc+ SHELL
script, which takes a three-digit number as an argument.

.Unzip Execute a quality control 
----
bash job-cram2fastq 056 FASTQ056.cram FASTQ056.recovered.fq
gzip FASTQ056.recovered.fq
----

.Execute a quality control 
----
bash job-fastq-qc 056 FASTQ056.recovered.fq.gz FASTQ056.prinseq.fq.gz 
----

In the +job-fastq-qc+ we take a raw fastq file to first remove adapter sequences
from the short reads in the fastq file, and to remove low quality 3' end parts.
In the +job-bwa-align+ we take the processed short reads to align them on a
reference genome.

.Align short reads using bwa and subread
----
bash job-bwa-align 056 FASTQ056.prinseq.fq.gz bwa/FASTQ056.sorted subread/FASTQ056.sorted
----

In the third stage of +job-de+ we take the short read alignment files to count
short reads mapped on genes for summarizing numbers of reads see +job-de+,
+job-de.R+.

.Two pairs of input and output files of +job-de+ stage
----
output/ua159/1/bwa/FASTQ056.sorted.bam
output/ua159/1/subread/FASTQ056.sorted.bam
output/ua159/1/bwa/FASTQ056.cl
output/ua159/1/subread/FASTQ056.cl
----

Counting mapped short reads may require memory exceeding the capacity of a
compute node. So, we divide alignments smaller pieces, for each of which we
count reads, and then sum the counts. Script +job-de+ does the former and
another script +job-de2+ does the latter.  

.Maximum number of lines for a smaller alignment file
----
CACRSCRIPT:/home/fs01/sc2265/Downloads/r-devel/b/bin/Rscript
----

Short reads mapped on a reference genome could be filtered out.

.Minimum mapping quality
----
MINMAPQ:30
----

.Minimum trimming quality
----
MINTRIMQ:20
----

.Maximum hours for zipping fastq files
----
CRAMWALLTIME:12
----
We use BWA to map reads for zipping them.

.Installed bwa and samtools
----
BWA:usr/bin/bwa-0.6.1
SAMTOOLS:usr/bin/samtools-0.1.18
PICARD:usr/bin/picard-tools-1.62
----
Download bwa and samtools at a directory in CAC cluster. Build and install them.
BWA's location would be $HOME/usr/bin/bwa-0.6.1.
Go to the working directory at your cluster, and execute +run-cram.sh+ script.

To change reference genomes replace the following three species file variables.

.Change reference genomes
----
REFGENOMEID:NC_004368
REFGENOMEFASTA:input/Streptococcus_agalactiae_NEM316/NC_004368.fna
REFGENOMEGFF:input/Streptococcus_agalactiae_NEM316/NC_004368.gff
----

fastq-sample
~~~~~~~~~~~~
The menu creates another FASTQ file from a given one.
Subsample the set of FASTQ files.
I subsample RNA-Seq short sequences. I can shorten RNA-Seq sequences.
I can keep reads with minimum lengths.

transcript-genecoverage
~~~~~~~~~~~~~~~~~~~~~~~
This creates an input file for Martin's ParaseRNAseq.

transcript-parsernaseq
~~~~~~~~~~~~~~~~~~~~~~
To fine a transcript map.

transcript-summary
~~~~~~~~~~~~~~~~~~
Transcripts are defined to be genomic features with constant expression. I use
RNA-Seq data to predict transcripts using either Martin's ParseRNAseq.
I summarize the transcripts with known genes, small RNAs, and other
information.


BWA Alignment
~~~~~~~~~~~~~
Call *cp-genome* to copy the genome file in FASTA format to the data directory.
Call *bwa-index-genome* just right after *cp-genome* menu. 
Call *bwa-align* to produce the sorted alignment in BAM format.
Call *bwa-mpileup* to create pileup and wiggle files.

Now, call *fastq-summary* again to see the
proportions of short reads mapped on the reference genome.

Call *bwa-align*, *bwa-samse*, *bwa-samtools-view*, *bwa-samtools-sort*, and
*bwa-samtools-bed* menus in order. 
Menus from *bwa-align* to *bwa-samtools-bed* can be run in a single command
using *bwa-batch-align-to-bed*, which creates a +batch+ file at the base
directory. Just execute the +batch+ file with BASH shell.

.BWA alignment procedure
. +bwa index+ Index a reference genome
. +bwa aln+ Align short reads on the reference genome
. +bwa samse+ Convert SAI to SAM
. +samtools view -bS+ Convert SAM to BAM
. +samtools sort+ Sort BAM
. +samtools view+ Convert BAM to SAM

*bwa-align* produce the sorted alignment in BAM format. I do not use
*bwa-samse*, *bwa-samtools-view*, *bwa-samtools-sort*.

Call menu *bwa-mpileup* to create a pileup file, and to create a wiggle file to
upload RNA-Seq sample tracks. The species file should have READDEPTH, which is
used in +samtools mpileup+ -d option value. If the uploaded track is limited by
the value you specified, you should increase the value.
----
READDEPTH:300000
----

*bwa-summary* creates +sum.pos+ files. For example, +sum.pos+ files contains three
columns: short read names, start, and end positions of the short reads in the
reference sequence.
*bwa-summary* creates summary files: number of reads, number of reads uniquely
mapped. 
*bwa-summary* finds the total number of reads, the number of reads mapped.
A +sum+ file, e.g.,  output/omz/1/bwa/FASTQ01.sum, contains RNA-Seq short
sequence file, total number of the reads, and the number of short reads mapped.

rna-rnaz
~~~~~~~~
Do we have any thing with this small RNA stuff?

anchor:Configuration[]

Configuration
-------------
Place a file called README in the directory of +conf+. You can copy
+conf/README.template+ to create +conf/README+. The file contains two kinds of
lines: one for comment, and the other for variable assignment. Comments shoud
start with # at the first column of a line. 

----
# Comment
----

A variable assignment should start without # at the first column. Variables tend
to be capitalized, and are followed by a colon, then a variable value. No spaces
are allowed. Give a project name as follows.

----
PROJECTNAME:streptoccus
----

All of the output files from *RNAseq Analysis* created in +output+ directory. We
might want to have a separate hard drive for saving those files because output
files can grow larger than any files in the main source files. We used a
symbolic link +output+ at the main directory to point to another directory that
is in a big hard drive. I want to work on the source code *RNAseq Analysis* in
Dropbox so that I can work at other places than the computer. I could use github
to update the source at one place, and pull the source at another place. This is
tedious. One final compromise is to set the output directory directly in the
configuration. Set _ROOTANALYSISDIR_ to a full file path. 

----
ROOTANALYSISDIR:/path/to/RNASeq-Analysis
----

We allow three modes of using *RNAseq Analysis*: local, remote, or cac.

.To execute jobs in your local machine
----
RUNMODE:local
----

.To execute jobs in a remote machine
----
RUNMODE:remote
----

.To execute jobs in a cluster machine such as CAC: http://www.cac.cornell.edu.
----
RUNMODE:cac
----

Set more variables if you execute jobs in a remote machine. We let the remote
machine be CAC, which is one of the cornell linux clusters. We are not sure what
other linux cluster options are available. If your cluster system is different
from one in CAC, you have to modify parts of the cluster job submission in SHELL
scripts. You are recommended to set up ssh login without password because we
need log in the remote machine to create directories and copy files back and
forth. See 
http://www.linuxproblem.org/art_9.html
or
http://smbjorklund.no/ssh-login-without-password-using-os-x.
You should set the number of CPUs available in a computing machine.

.To set the number of CPUs for running jobs. 
----
NUMBERCPU:8
----

You need to specify a combination of a user name and a domain name. 

.To set user ID and login address 
----
CAC_USERNAME:yourUserID
CAC_LOGIN:compute.domain.name
----

Set the _CAC_LOGIN_ variable even if you execute jobs in your local machine.

.To set user ID and login address for local mode
----
CAC_USERNAME:yourUserID
CAC_LOGIN:localhost
----

We could have two unix machines: one for computing and another for genome
browser. Use _X11_USERNAME_ and _X11_LOGIN_ to set a machine for genome
browser.

.To set user ID and login address
----
X11_USERNAME:yourUserIDforGenomeBrowser
X11_LOGIN:genome.browser.doman.name
----

We use the CAC cluster for computing, which may need access information. A batch
script for the cluster would have following header lines.

----
#PBS -A ${BATCHACCESS}
#PBS -q ${QUEUENAME}
#PBS -M ${BATCHEMAIL}
----

The three variables above are replaced by values from the following lines.

----
BATCHACCESS:yourAccessID
QUEUENAME:yourQueueName
BATCHEMAIL:you@email.com
----

Sometime you may not want to get notified from the cluster when jobs are
finished. Then, set _EMAILON_ to FALSE. If you want to get notified, then set it
to TRUE.

----
EMAILON:FALSE
or 
EMAILON:TRUE
----

In the computing machine, you need to have two kinds of directory: one is for
storing input and output files, and the other for executing scripts. Please,
specify a full path not a relative one. You must specify _ROUTPUTDIR_ whatever
_RUNMODE_ is.
While running jobs, input and output files are stored in _ROUTPUTDIR_ directory.
When jobs are finished, files can be copied to the output directory of the base
directory in your local machine. This may be confusing, but convenient because
we can easily delete _ROUTPUTDIR_ directory when we do not need it. We would
want to save files in the output directory in your local machine. Use a full
path not a relative one.

----
ROUTPUTDIR:/path/to/output
----

We use other tools or packages. You need to specify paths for those tools.
Please, find the installation section to know how to install them into the
computing machine.

----
BWA:usr/bin/bwa-0.6.1/bwa
SAMTOOLS:usr/bin/samtools-0.1.18/samtools
PRINSEQ:usr/bin/prinseq-lite-0.17.4/prinseq-lite.pl
PICARD:usr/bin/picard-tools-1.67
CRAMTOOLS:usr/bin/cramtools-0.8.jar
PARSERNASEQ:usr/bin/ParseRNAseq
PYTHON:/opt/epd/bin/python2.7
CUTADAPT:/home/fs01/sc2265/usr/bin/cutadapt-1.0/cutadapt
CACRSCRIPT:/home/fs01/sc2265/Downloads/r-devel/b/bin/Rscript
----

anchor:Installation[]

Installation
------------
Software packages are employed for the analysis. These should be installed on
the local or remote machine. First, create directories called +downloads+ and
+build+. If you use your local machine, follow this instruction in your machine.
You have to log in your remote machine if you use other machine such as a linux
cluster.

----
$ mkdir -p downloads/build
----

Create a +bin+ directory to save executable files.

----
$ mkdir -p $HOME/usr/bin
----

BWA
~~~
Dowanload BWA source code available at http://bio-bwa.sourceforge.net. 

----
$ downloads/bwa-0.6.1.tar.bz2
----

Extract the file and compile it.

----
$ cd downloads/build
$ tar jxf ../bwa-0.6.1.tar.bz2
$ cd bwa-0.6.1; make; cd ..
$ mv bwa-0.6.1 $HOME/usr/bin
----

Edit +conf/README+ if necessary; Add the following line. The base directory is
$HOME or your home directory. Shell variable $BWA is replaced by
+/home/userid/usr/bin/bwa-0.6.1/bwa+.

----
BWA:usr/bin/bwa-0.6.1/bwa
----

SAMTools
~~~~~~~~
Download SAMtools available at http://samtools.sourceforge.net.

----
$ downloads/samtools-0.1.18.tar.bz2
----

Extract the file and compile it.

----
$ cd downloads/build
$ tar jxf ../samtools-0.1.18.tar.bz2
$ cd samtools-0.1.18; make; cd ..
$ mv samtools-0.1.18 $HOME/usr/bin
----

Edit +conf/README+ if necessary; Add the following line. The base directory is
$HOME or your home directory. Shell variable $SAMTOOLS is replaced by
+/home/userid/usr/bin/samtools-0.1.18/samtools+.

----
SAMTOOLS:usr/bin/samtools-0.1.18/samtools
----

subread
~~~~~~~
Download subread available at http://subread.sourceforge.net. 
Another short read aligner. This is used in menu *batch2*.
As of April 2012, it did not support Mac OS X. Authors said that they would make
a Mac OS X version available in 2012.

prinseq
~~~~~~~
Download a prinseq lite version available at http://prinseq.sourceforge.net.
Extract the file and move the directory.

----
$ cd downloads/build
$ tar zxf ../prinseq-lite-0.17.4.tar.gz
$ mv prinseq-lite-0.17.4 $HOME/usr/bin
----

Edit +conf/README+ if necessary; Add the following line. The base directory is
$HOME or your home directory. Shell variable $PRINSEQ is replaced by
+/home/userid/usr/bin/prinseq-lite-0.17.4/prinseq-lite.pl+.

----
PRINSEQ:usr/bin/prinseq-lite-0.17.4/prinseq-lite.pl
----

Picard
~~~~~~
Download Picard available at http://picard.sourceforge.net. Unzip the file and
move directories.

----
$ cd downloads/build
$ unzip ../picard-tools-1.65.zip
$ mv picard-tools-1.65 $HOME/usr/bin
$ mv snappy-java-1.0.3-rc3.jar $HOME/usr/bin
----

Edit +conf/README+ if necessary; Add the following line. The base directory is
$HOME or your home directory. Shell variable $PICARD is replaced by
+/home/userid/usr/bin/picard-tools-1.65+.

----
PICARD:usr/bin/picard-tools-1.65
----

CRAM Toolkit
~~~~~~~~~~~~
Download CRAM Toolkit available at http://www.ebi.ac.uk/ena/about/cram_toolkit.
Move the file to +$HOME/usr/bin+.

----
$ cd downloads/build
$ mv ../cramtools.jar $HOME/usr/bin
----

Edit +conf/README+ if necessary; Add the following line. The base directory is
$HOME or your home directory. Shell variable $CRAMTOOLS is replaced by
+/home/userid/usr/bin/cramtools.jar+.

----
CRAMTOOLS:usr/bin/cramtools.jar
----

cutadapt
~~~~~~~~
Download cutadapt available at http://code.google.com/p/cutadapt.

----
$ cd downloads/build
$ tar zxf ../cutadapt-1.0.tar.gz 
$ mv cutadapt-1.0 $HOME/usr/bin
----

Edit +conf/README+ if necessary; Add the following line. The base directory is
$HOME or your home directory. Note that _CUTADAPT_ must be the absolute path of
the binary executable. We would call python with the executable. Do not use a
relative file path.

----
CUTADAPT:/home/user/usr/bin/cutadapt-1.0/cutadapt
----

NOTE:The following prorams need to be checked. I have not yet time to edit the
following description of the installation.

----
$ python setup.py build
$ sudo python setup.py install
CUTADAPT:/usr/local/bin/cutadapt
----

.To install cutadapt in a linux cluster
----
python2.7 setup.py build_ext -i
python2.7 path/to/cutadapt --help
----

python
~~~~~~
Set _PYTHON_ variable to a file.

----
PYTHON:/opt/epd/bin/python2.7
----

Rscript
~~~~~~~
Set _CACRSCRIPT_ variable.

----
CACRSCRIPT:/home/fs01/sc2265/Downloads/r-devel/b/bin/Rscript
----

BOWTIE
~~~~~~
Download BOWTIE and install it under +src+ directory. The following command
should print a help message from it. Edit +conf/README+ if necessary.
----
$ src/bowtie-0.12.7/bowtie
----


segemehl
~~~~~~~~
Download segemehl at http://www.bioinf.uni-leipzig.de/Software/segemehl. You
could compile the source in this repository of rnaseq-analysis.
http://www.bioinf.uni-leipzig.de/Software/segemehl/
----
$ cd src/segemehl_0_0_9_4
$ make
----

FASTAX-Toolkit
~~~~~~~~~~~~~~
Download FASTAX-Toolkit at
http://hannonlab.cshl.edu/fastx_toolkit/fastx_toolkit-0.0.13.tar.bz2
and 
http://hannonlab.cshl.edu/fastx_toolkit/libgtextutils-0.6.tar.bz2.

edgeR
~~~~~
In R, run the two lines of
----
source("http://www.bioconductor.org/biocLite.R")
biocLite("edgeR")
----

DEGseq
~~~~~~
In R, run the two lines of
----
source("http://www.bioconductor.org/biocLite.R")
biocLite("DEGseq")
----

TopHat
~~~~~~
Download the Mac OS X x86_64 binary from http://tophat.cbcb.umd.edu[here].
Untar it and add the directory to PATH so that I can run it without full path.

Cufflinks
~~~~~~~~~
Download the Mac OS X x86_64 binary from http://cufflinks.cbcb.umd.edu[here].
Untar it and add the directory to PATH so that I can run it without full path

ncbi-blast
~~~~~~~~~~

ftp://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/LATEST/ 
ncbi-blast-2.2.25+-x64-linux.tar.gz
is used in the cluster.

MUSCLE
~~~~~~

http://www.drive5.com/muscle/downloads3.8.31/muscle3.8.31_i86linux64.tar.gz

.Create a +build+ directory at the base directory +run/rnaseq/110111+ of a cluster.
----
cac:run/rnaseq/110111/build/muscle3.8.31_i86linux64  
cac:run/rnaseq/110111/build/ncbi-blast-2.2.25+
cac:run/rnaseq/110111/build/RNAz-2.1
----

RNAz
~~~~
http://www.tbi.univie.ac.at/~wash/RNAz/

----
wget http://www.tbi.univie.ac.at/~wash/RNAz/RNAz-2.1.tar.gz
wget http://www.tbi.univie.ac.at/RNA/ViennaRNA-1.8.5.tar.gz
----

In the CAC:
----
mkdir b
cd b
../configure --prefix=$HOME/usr 
----

uniprot90
~~~~~~~~~
wget ftp://ftp.uniprot.org/pub/databases/uniprot/uniref/uniref90/uniref90.fasta

RNAplex
~~~~~~~
http://www.bioinf.uni-leipzig.de/Software/RNAplex/

RNAz
~~~~
https://github.com/wash/rnaz

Vienna RNA Package
~~~~~~~~~~~~~~~~~~
http://www.tbi.univie.ac.at/~ivo/RNA/RNAplfold.html


anchor:SpeciesFile[]

Species File
------------
A setup for *RNAseq Analysis* is described in a species file in +species+
directory.  Choose a species name for a species file. Create a file with the
name, and place it in the directory of +species+. You can use
+species/template+. As the +conf/README+ file, a species file contains two
kinds of lines: one for comment, and the other for variable assignment. Comments
shoud start with # at the first column of a line. 

----
# Comment
----

A variable assignment should start without # at the first column. Variables tend
to be capitalized, and are followed by a colon, then a variable value. No spaces
are allowed.  

.Variable in a species file
----
VARIABLE:value
----

Check a list of species file variables in the following.  Note that we must have
a single variable. Multiple instances of species file variables would cause
problems.

.Check the following spcies file variables
. fastq files
. quality score scheme
. adapter sequences
. fastq file indices in _FASTQFILES_
. fastq file labels in _FASTQLABEL_
. cluster working directory in _CACWORKDIR_
. reference genome ID in _REFGENOMEID_
. reference genome genbank file in _REFGENOMEGENBANK_
. reference genome fasta file in _REFGENOMEFASTA_
. reference genome annotation file in _REFGENOMEGFF_
. reference genome annotation file in _REFGENOMEPTT_
. reference genome annotation TrancriptDb file in _REFGENOMETXDB_
. set _SINGLECHROMOSOME_ to TRUE or FALSE
. pipeline wall time in _QCALIGNDEWALLTIME_
. minimum alignment mapping quality in _MINMAPQ_
. minimum base quality to trim 3' end in _MINTRIMQ_
. Rscript path in _CACRSCRIPT_
. set _TESTFASTQ_ to integers

fastq files
~~~~~~~~~~~
Firstly, place fastq files in your _ROOTANALYSISDIR_ in the computer.
Then, specify locations of the fastq files. Variables are prefixed _FASTQ_ with
three-digit numbers with zeros prepended. Currently, the file extension must be
fq and files must be zipped using +gzip+. So, files should end with +fq.gz+. Use
a path relative to _ROOTANALYSISDIR_ directory.

.fastq files
----
FASTQ001:path/to/file1.fq.gz
FASTQ002:path/to/file2.fq.gz
----

quality score
~~~~~~~~~~~~~
Quality scores can be phred33 or phred64. Use a value of "illumina" for phred64,
and a value of "sanger" for phred33.  Variables are prefixed _QUALITYSCORE_ with
three-digit numbers with zeros prepended. Because each fastq file has a
distinct quality score scheme, you need to specify quality score schemes as many
times as fastq files.

.Quality scores schemes
----
QUALITYSCORE001:illumina
QUALITYSCORE002:sanger
----

adapter sequences
~~~~~~~~~~~~~~~~~
Each fastq file is associated with an Illumina adapter sequence. They must be
specified, and are used to remove adapter sequences in short reads.  Variables
are prefixed _ADAPTER_ with three-digit numbers with zeros prepended. 

.Adapter sequences
----
ADAPTER001:GATCGGAAGAGCACACGTCTGAACTCCAGTCACCGATGTATCTCGTATGCCGTCTTCTGCTTG
ADAPTER002:GATCGGAAGAGCACACGTCTGAACTCCAGTCACTGACCAATCTCGTATGCCGTCTTCTGCTTG
----

fastq file indices and labels
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
You may wish to process all of fastq files, or some of them. Specify which fastq
files you wish to use using _FASTQFILES_ variable. Use _FASTQLABEL_ to group
different fastq files. Labels are used for the purpose of differential
expression study. They are saved in a file called +count.txt.index+.

.File indices for fastQ files
----
FASTQFILES:1 2
FASTQLABEL:UA159 TW1
----

cluster working directory
~~~~~~~~~~~~~~~~~~~~~~~~~
After creating all of the scripts in your local machine, you would submit jobs
at a directory in the cluster. You need to create the directory while you
prepare a *RNASeq Analysis* by editing a species file.

.Cluster working directory
----
CACWORKDIR:run/rnaseq/022712
----

.Create the working directory
----
cac> mkdir -p run/rnaseq/022712
----

reference genome
~~~~~~~~~~~~~~~~
If you want to change the reference genome, change the following _REFGENOMEID_
variable.

----
REFGENOMEID:NC_004350
----

Set the path of a reference genome genbank file in _REFGENOMEGENBANK_. Use a
path relative to your _ROOTANALYSISDIR_ directory. For example, you would have a directory
called +data+ in *RNASeq-Analysis* _ROOTANALYSISDIR_ directory. 
Use a path relative to _ROOTANALYSISDIR_ directory. 

----
REFGENOMEGENBANK:path/to/NC_004350.gbk
----

The path _ROOTANALYSISDIR_ must be set in the configuration file, or
+conf/README+ (see the section <<Configuration>>).

----
ROOTANALYSISDIR:/path/to/RNASeq-Analysis
----

So the genbank file must be at 

----
/path/to/RNASeq-Analysis/path/to/NC_004350.gbk
----

To map short reads on a reference genome, you must specify the file paths of
reference genome files and gene annotations. The reference genome sequence is in
FASTA format. Each sequence represents a contiguous genome. A complete bacterial
genome can be a single sequence because only one chromosome is available.
Genomes can consist of multiple chromosomes. The FASTA file would contain
multiple FASTA sequences. Because it is convenient to assume sequence names,
we rename each sequence using chromosome numbers in the FASTA file of a genome. 
For example, the first line of a FASTA file for a reference genome must be 

----
>chr1
----

Change the names of other sequences accordingly: chr2 for the second chrmosome.
An incomplete bacterial genome would have multiple contigs, each of which can be
considered a chromosome. 
Use a path relative to _ROOTANALYSISDIR_ directory. 
Note that we also have to change chromsome name in a gff file as well. If there
are other annotation files, change the names accordingly.

.Reference genomes
----
REFGENOMEFASTA:data/to/NC_004350.fna
REFGENOMEGFF:path/to/NC_004350.gff
----

If there are multiple sequences in the reference FASTA file, then 
set _SINGLECHROMOSOME_ to FALSE.

----
SINGLECHROMOSOME:TRUE
----

We use genome annotations from different sources. We could use a genbank file, a
gff file, or ptt file. I do not know what annotation files I should use. We
can extract annotations from a genbank file. In the mean time, we also need to
provide ptt file.  Use a path relative to _ROOTANALYSISDIR_ directory. 

----
REFGENOMEPTT:data/NC_004350.ptt
----

We can convert a gff file to a txdb file. See +R/gff2txdb.R+ for detail.
Use a path relative to _ROOTANALYSISDIR_ directory. 

----
REFGENOMETXDB:path/to/NC_004350.txdb
----

pipeline wall time
~~~~~~~~~~~~~~~~~~
Set the maximum compute time for aligning and counting short reads.

.pipeline wall time
----
QCALIGNDEWALLTIME:8
----

.BWA alignment wall time
----
BWAALIGNWALLTIME:24
----

minimum alignment mapping quality
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
We filter out short reads with bad mapping quality scores.

----
MINMAPQ:30
----

minimum base quality to trim 3' end
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
We trim the 3' end of short reads using a threshold of base quality.

----
MINTRIMQ:20
----

Rscript path
~~~~~~~~~~~~
Specify a full path of +Rscript+ executable.

----
CACRSCRIPT:/path/to/Rscript
----

Test FASTQ file numbers
~~~~~~~~~~~~~~~~~~~~~~~
Specify FASTQ numbers for creating test FASTQ files.
----
TESTFASTQ:101 102 103 104
----

optional
~~~~~~~~

You need to specify a genome for cramming a FASTQ file.

.cram reference genome fasta file 
----
CRAMGENOMEFASTA:data/NC_004350.fna
----

Set the maximum computing time in hours for cramming a FASTQ file.

.cram wall time
----
CRAMWALLTIME:6
----

We can test *RNASeq-Analysis* using the following lines.

.set bwa options
----
BWAOPTION: options
----

We need to document the following documents.

.UCSC genome browsers related variables
----
DBNAME:SmuUA159v2
CLADENAME:streptococcus
GENOMENAME:S. mutans UA159
ASSEMBLYNAME:Mar 13 2012
REFGENOMENAME:gi|24378532|ref|NC_004350.1|
----

----
PARSERNASEQNNODE:1
PARSERNASEQWALLTIME:36
RNAZNNODE:1
RNAZWALLTIME:144
----

Bash variables
--------------
The directory +sh+ contains a number of BASH SHELL scripts. I describe 
often-used variables.

.fastQ file name variable
----
FASTQNUM=FASTQ$(printf "%03d" $g)
----

batch3.sh
~~~~~~~~~

Function _batch3-variable_ creates often-used shell variables.
_ROOTANALYSISDIR_ is set to a full file path by configuration.
_SPECIESFILE_ is the species file name relative to the directory where a +run+
is executed. _OUTPUTDIR_ is the output directory relative to _ROOTANALYSISDIR_. 
_BASEDIR_ is the species filenamed directory at _OUTPUTDIR_. _NUMBERDIR_ is a
directory 1 (repetition number) at _BASEDIR_. _DATADIR_ is placed at
_NUMBERDIR_. _BWADIR_ is also at _NUMBERDIR_, and so is _RUNANALYSIS_. Consider
that _DATADIR_ contains input files, _BWADIR_ contains processed files, and
_RUNANALYSIS_ contains output files. We have similar directory names in a remote
machine: _RBASEDIR_, _RNUMBERDIR_, _RDATADIR_, _RBWADIR_, and _RANALYSISDIR_.
We have similar directory names in a computing machine:
_CBASEDIR_, _CNUMBERDIR_, _CDATADIR_, _CBWADIR_, and _CANALYSISDIR_.

Function _batch3-output_ creates _DATADIR_, _BWADIR_, and _RUNANALYSIS_
directories.

Function _batch3-speciesfile_ creates shell variables set by _SPECIESFILE_.
_FASTQFILES_ is a list of numbers separated by spaces. _FASTQLABEL_ is a list of
sample names. _CACWORKDIR_ is the directory at which we submit jobs. 
_REFGENOMEFASTA_ and _REFGENOMETXDB_ are genbank and TranscriptDb files. They
should be at _ROOTANALYSISDIR_.  _QCALIGNDEWALLTIME_ is the limit of execution
time in hours.  _MINMAPQ_ is the minimum alignment mapping quality.
_MINTRIMQ_ is the minimum base quality to trim 3' end. 

Function _batch3-push-data_ help send files to the remote machine for job
submission by creating a shell script, +push-data.sh+. Execute the shell script
to send files for processing.

Function _batch3-get-data_ creates a shell script to get resulting files from
the remote machine. The files are +count.txt+, +count.multiple.txt+,
+qualPlot.pdf+, and +stat1.tex+.

Function _batch3-run-qcalignde_ creates most of shell and R scripts. 

File +run-qcalignde.sh+ is the main script to be executed when submitting jobs
to the cluster. It replaces a string named PBSARRAYSIZE with the number of FASTQ
files in +batch-qcalignde.sh+, and submit the batch file.

File +batch-qcalignde.sh+ is the batch script that is submitted to the cluster.
A function called +process-data+ in the batch script executes a series of jobs
for a FASTQ file. It first copies a FASTQ file from the remote data directory
called _RDATADIR_. We should find the FASTQ file in the remote data directory.
The file is copied to the parallel directory in the compute node, _CDATADIR_.
We use +job-stat+ to process the FASTQ file. 
We use +job-fastqc+ to remove parts of or whole short reads with low quality.
We use +job-bwa-align+ to align reads to a reference genome.
We use +job-de+ to count reads aligned to the reference genome.

Function _batch3-make-job_ creates all of the job files in shell and R scripts.
Bash script +job-stat+ takes a three-digit number, a gzipped FASTQ file name,
and an output RData file name.
Bash script +job-fastqc+ takes a three-digit number, a gzipped FASTQ file name,
and another gzipped FASTQ file name (output). 
Bash script +job-bwa-align+ takes a three-digit number (FASTQ ID), an input
gzipped FASTQ file name, and an output BAM file base name without the extension
of bam.
Bash script +job-de+ takes a sorted BAM file, the number of reads in the sorted
BAM file, and the number of reads in FASTQ file used as an input to bash script
+job-bwa-align+.
Bash scripts +job-simulate+ and +job-check+ create a small test data to check
the alignment and count procedure.

File +feature-txnc.txt+ contains R scripts to use the txdb file specified in a spceis file. This could be the key file for handling gene annotations. This file is added to R script files: +job-de.R+, +job-de-sum.R+, and +job-simulate.R+. We use R function _transcripts_ to extract regions, on which we count reads mapped. R function _cds_ extracts CDS regions. R package _GenomicFeatures_ features the two functions. I need a simple example files for handling R scripts. They are easy to use, and also easy to forget. Let's see what it does. We construct a transcript map with meta data. A transcript is of type being either "CDS" or "NOCDS." Regions not within the transcript map are of type being "NG." An R variable called _feature.txnc_ contains transcripts with 6 columns: seqnames, ranges, strand, tx_id, tx_name, and type. 

R script file +job-de.R+ takes takes a sorted BAM file, the number of reads in the sorted BAM file, and the number of reads in FASTQ file used as an input to bash script +job-bwa-align+. This is the same list of arguments as those of +job-de+. The first argument is used create the output file name by appending ".cl" to the sorted bam file. R package GenomicFeatures is used to extract annotation. The statistics of short reads are incomplete (FIXME). It bothers me that I did not have a complete information about statistics. R package GenomicRanges features summarizeOverlaps, which counts short reads mapped on amap of transcripts. _cl_ contains counts. _cl.nc_ is a subset of _cl_ for nongenic regions. _cl.multiple_ contains reads mapped on multiple places. _cl.multiple.nc_ is a subset of nongenic regions of _cl.multiple_. _cl.multiple.nocds_ is a subset of non-CDS regions of _cl.multiple_. The transcript map in txdb contains genes, non-genic "NG", and non-CDS "NOCDS". We have 4 values for the number of reads. _num.total.read_ is the number of total reads in the FASTQ file. We align _num.n.read_ reads on a reference genome. The bam file contains _num.mapped.read_ reads. Among them _num.unique.read_ reads are aligned with minimum quality score, _MINMAPQ_. _bv_ is an R _GappedAlignments_ object returned by R function _readBamGappedAlignments_ of package _Rsamtools_. _bv_ contains mapped reads with minimum of _MINMAPQ_ mapping quality score. _bv.multiple_ is an R _GappedAlignments_ object that contains mapped reads with mapping quality score less than _MINMAPQ_. We report overlapping genes. ``Now, I see a little bit what I did.'' 

R function _makeTranscriptDb_ requires a few R data frames in its arguments. An argument, transcripts, consists of transcript ID (integer), transcript name (character), chromosome name (character), strand ("+", "-"), start position (integer), end position (integer). A second argument, splicings, consists of transcript ID (integer A), exon ID (integer B), exon name (character), exon start and end (integers), cds start and end (integers). We create a txdb file based on the following rationale. An exon is a transcript. The exon or the transcript may contain a CDS. See the R script in _feature-txnc.txt_ how a txdb file is used.

Bash script +job-de-sum+ calls its R script. It passes _RBWADIR_ directory and a file that contains FASTQ IDs to the R script. R script file +job-de-sum.R+ takes a BWADIR directory, and a file containing FASTQ IDs. Use the ``cl'' files for the FASTQ IDs to create a table of counts. We create several _count.table_ R variables. +job-de.R+ creates _cl_, _cl.cds_, _cl.nocds_, _cl.tx_, and _cl.ng_. For these count variables, we have _count.table_, _count.table.cds_, _count.table.nocds_, and the like. This creates a number of files: 'count', 'count.cds', 'count.nocds', 'count.tx', and 'count.ng'. For multiple matched reads, we have 'count.m', 'count.m.cds', 'count.m.nocds', 'count.m.tx', and 'count.m.ng'. R script 'job-de-sum.R' also creates a table of statistics. Column +a+ is the number of reads in the FASTQ file. Column +b+ is the number of reads after quality control using PRINSEQ. Column +c+ is the number of reads in the sorted BAM file. Column +d+ is the number of counted reads multiply mapped on non-CDS transcripts. Column +e+ is the number of reads uniquely mapped. Column +e+ is the number of counted reads uniquely mapped on transcripts. Column +f+ is the number of counted reads uniquely mapped non-transcript regions.

Bash script +job-simulate+ creates test FASTQ files using txdb annotation. R script +job-simulate.R+ takes _FASTQNUM_ as the only argument.  Because we execute +job-simulate+ at the remote computer not at the compute node, we use _RBWADIR_ and _RDATADIR_ directories not _CBWADIR_ or _CDATADIR_. We use _feature.txnc_ or the complete feature to create short reads. We store sampled reads in _read.GA_. We sample reads from genes with 1,000 base pairs per chromosome. We use positions of reads to create a _GappedAlignments_ object and add it to _read.GA_. We use the positions to extract DNA sequences, and write them to a FASTQ file. Ignore warnings, which arise when adding _GappedAlignments_ with different chromosome configurations. 

Files
-----

AUTHORS
~~~~~~~
Sang Chul Choi uses Perl, R, and NGS programs to analyze bacterial transcriptome. Charles Danko guides the development in the early stage of the development of *RNAseq Analysis*.

COPYING
~~~~~~~
The GNU General Public License. 

INSTALL
~~~~~~~
The instruction of installing RNAseq Analysis.

NEWS
~~~~
A list of user-visible changes to *RNAseq Analysis* worth mentioning. 

R
~
R scripts.

README
~~~~~~
A README of the root directory.

THANKS
~~~~~~
People help the development of *RNAseq Analysis*.

TODO
~~~~
New features of *RNAseq Analysis*.

bin
~~~
Binary or shell script files. 

c
~
A shell script that uses +asciidoc+ to convert +doc/Manual+ to an html file.

conf
~~~~
The *RNAseq Analysis* is configured using the +README+ in the +conf+ directory.

doc
~~~
Users should refer to documentation in +doc+ directory, which also contains +lyx+ files for potential publications from the analysis of bacterial transcriptome.

package
~~~~~~~
We use R-based analyses to postprocess the results from computationally intensive analyses, which are mostly done in *RNAseq Analysis*. Parts of the analyses can be incorporated in a manuscript for publication as a part of the result section.

pl
~~
Perl scripts.

run
~~~
It shows a menu of commands provided by *RNAseq Analysis*.

sh
~~
Bash scripts.

species
~~~~~~~
Sample analysis files. This directory can be used for your analyses if _ROOTANALYSISDIR_ variable in +conf+ is set to the source code directory of *RNAseq Analysis*.

src
~~~
C, or C++ source codes.

ucsc
~~~~
Files for a UCSC genome browser.

Features
--------

cram
~~~~
Because short reads files tend to be large, it would be convenient to zip them
so that we can save storage and time of transfer. Although it is under
development, it seems to be a good idea to use a program called +cram+. Please,
make sure that you use the same version of the program in both zipping and
unzipping. You also need to make sure that you use the same reference genome.
Use the following command after executing +batch2+ menu.

.Cram short reads at _CACWORKDIR_
----
$ bash run-cram.sh
----

FIXME: the following scripts can be run separately in the cluster. They need
documentations.
I used to have separate scripts for quality control, alignment, and counting
reads. Although this was fine, it would produce unnecessary intermediate files
that could be very large. Because accumulated large files could be too big for
the compute node to host, this might cause problems in the pipeline. The
followings are descriptions for the separate analyses. They can be useful in
understanding separate analyses that are integrated in +run-qcalignde.sh+.

.To align reads step-by-step
----
$ bash run-fastqc.sh
$ bash run-cram.sh
$ bash run-cram2fastq.sh
$ bash run-bwa-align.sh
$ bash run-bias.sh
$ bash run-coverage.sh       <- takes time
$ bash run-coverage-pull.sh
$ bash run-parsernaseq.sh
$ bash run-ucsc.sh
$ bash run-de.sh -> not yet
----

.To create an input file for tux
----
$ bash job-coverage-start-end.sh
----
job files are supposed to be run in the compute node. Those with sh extension
would be run in the main node.

.To count reads
----
$ bash run-qcalignde.sh 
----
+run-qcalignde.sh+ includes fastqc, bwa-align, and de.

+run-fastqc.sh+ converts +data/FASTQ001.fq.gz+ to +bwa/FASTQ001.prinseq.fq.gz+.

+run-cram.sh+ converts +bwa/FASTQ001.prinseq.fq.gz+ to +bwa/FASTQ001.cram+.

+run-cram2fastq.sh+ converts +bwa/FASTQ001.cram+ to +bwa/FASTQ001.recovered.fq.gz+.

+job-stat+ converts +bwa/FASTQ001.fq.gz+ to +bwa/FASTQ001.fq.qualPlot.RData+.

+run-bwa-align.sh+ converts +bwa/FASTQ001.recovered.fq.gz+ to +bwa/FASTQ001.sorted.bam+.

+run-bias.sh+ converts +bwa/FASTQ001.sorted.bam+ to +bwa/FASTQ001.yml+.

+run-coverage.sh+ converts +bwa/FASTQ001.sorted.bam+ and +bwa/FASTQ001.yml+ to
+bwa/FASTQ001.cvg.*+.

+run-coverage-pull.sh+ converts +bwa/FASTQ001.cvg.*+ to +bwa/FASTQ001.coverage.RData+.
and +bwa/FASTQ001.wig+.

+run-fastqc.sh+ can use multiple CPUs by splitting FASTQ files, each of which is
processed by cutadapt and prinseq.

.To filter out the raw fastq files for quality control
----
bash job-fastqc 001 FASTQ001.fq.gz FASTQ001.prinseq.fq.gz 
----

.To align short reads on a reference genome
----
bash job-bwa-align 001 FASTQ001.prinseq.fq.gz FASTQ001.sorted 
----

+run-coverage.sh+ can use multiple nodes. BAM files are copied to each node
computer and copied again because readGappedAlignments(bamFile) R function
crashes when it tries to read a file from many computers.

+run-parsernaseq.sh+ creates +bwa/FASTQ001.parsernaseq+, +bwa/FASTQ001.bed2+ and 
+bwa/FASTQ001.operon+. 
File +bwa/FASTQ001.bed2+ is the ParseRNAseq output file in BED format.
File +bwa/FASTQ001.operon+ is another BED file of the transcript calls with
strand information inferred from genes annotations.

+run-ucsc.sh+ creates scripts and files to upload the genome browser.
----
$ bash job-ucsc-bed
----

+run-de.sh+ converts +bwa/FASTQ001.sorted.bam+ to +bwa/FASTQ001.sorted.bam.cl+.

Does +run-de.sh+ do this? We do not have that.

Randomly sample about 5 percent of the short reads.
awk 'BEGIN {srand()} !/^$/ {if (rand() <= .05 && NR%4==0) for ( o = 1; o <= 4; o++ ) {getline; print}}'

.Sample 0.1 percent of the total reads
----
fastq-sample.sh FASTQ056.fq.gz FASTQ056-0.001.fq.gz 0.001
----

What is this?
~~~~~~~~~~~~~

I wished to answer to the question of fidning genes that are in smu21 but not in
ua159. In order to do that I need to first extract protein coding DNA sequences
from smu21 and ua159. Compare the two sets of gene sequences using BLAST. We
extract DNA sequences using parts of the R script in +job-simulate.R+. 

.To extract DNA sequences from the genome using gff annotation
----
cac$ bash job-extract
----
